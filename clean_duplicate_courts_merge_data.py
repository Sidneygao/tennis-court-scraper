#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¸…ç†é‡å¤åœºé¦†æ—¶åˆå¹¶æœ‰æ•ˆæ•°æ®ï¼Œä¿ç•™æ¯ä¸ªåœºé¦†åç§°çš„ç¬¬ä¸€ä¸ªè®°å½•
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.database import SessionLocal
from app.models import TennisCourt, CourtDetail
from collections import defaultdict
import json

def merge_court_data(kept_court, duplicate_courts):
    """åˆå¹¶åœºé¦†æ•°æ®ï¼Œå°†é‡å¤åœºé¦†çš„æœ‰æ•ˆæ•°æ®åˆå¹¶åˆ°ä¿ç•™çš„åœºé¦†ä¸­"""
    # åˆå¹¶åŸºæœ¬ä¿¡æ¯
    for duplicate in duplicate_courts:
        # å¦‚æœä¿ç•™çš„åœºé¦†ç¼ºå°‘æŸäº›ä¿¡æ¯ï¼Œä»é‡å¤åœºé¦†ä¸­è¡¥å……
        if not kept_court.phone and duplicate.phone:
            kept_court.phone = duplicate.phone
        if not kept_court.address and duplicate.address:
            kept_court.address = duplicate.address
        if not kept_court.court_type and duplicate.court_type:
            kept_court.court_type = duplicate.court_type
        if not kept_court.area and duplicate.area:
            kept_court.area = duplicate.area
        if not kept_court.latitude and duplicate.latitude:
            kept_court.latitude = duplicate.latitude
        if not kept_court.longitude and duplicate.longitude:
            kept_court.longitude = duplicate.longitude

def merge_detail_data(kept_detail, duplicate_details):
    """åˆå¹¶è¯¦æƒ…æ•°æ®ï¼Œå°†é‡å¤åœºé¦†è¯¦æƒ…ä¸­çš„æœ‰æ•ˆæ•°æ®åˆå¹¶åˆ°ä¿ç•™çš„è¯¦æƒ…ä¸­"""
    for duplicate in duplicate_details:
        if not duplicate:
            continue
            
        # åˆå¹¶ä»·æ ¼æ•°æ® - ä¼˜å…ˆä¿ç•™éBINGçš„ä»·æ ¼æ•°æ®
        if not kept_detail.merged_prices and duplicate.merged_prices:
            kept_detail.merged_prices = duplicate.merged_prices
        elif kept_detail.merged_prices and duplicate.merged_prices:
            # å¦‚æœä¸¤è€…éƒ½æœ‰ä»·æ ¼æ•°æ®ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰éBINGçš„ä»·æ ¼
            try:
                kept_prices = json.loads(kept_detail.merged_prices) if kept_detail.merged_prices else []
                dup_prices = json.loads(duplicate.merged_prices) if duplicate.merged_prices else []
                
                # æ£€æŸ¥æ˜¯å¦æœ‰éBINGçš„ä»·æ ¼æ•°æ®
                kept_has_non_bing = any(p.get('source') != 'BING' for p in kept_prices)
                dup_has_non_bing = any(p.get('source') != 'BING' for p in dup_prices)
                
                # å¦‚æœä¿ç•™çš„è®°å½•åªæœ‰BINGä»·æ ¼ï¼Œè€Œé‡å¤è®°å½•æœ‰éBINGä»·æ ¼ï¼Œåˆ™ä½¿ç”¨é‡å¤è®°å½•
                if not kept_has_non_bing and dup_has_non_bing:
                    kept_detail.merged_prices = duplicate.merged_prices
            except:
                pass
        
        # åˆå¹¶å…¶ä»–è¯¦æƒ…å­—æ®µ
        if not kept_detail.dianping_prices and duplicate.dianping_prices:
            kept_detail.dianping_prices = duplicate.dianping_prices
        if not kept_detail.meituan_prices and duplicate.meituan_prices:
            kept_detail.meituan_prices = duplicate.meituan_prices
        if not kept_detail.bing_prices and duplicate.bing_prices:
            kept_detail.bing_prices = duplicate.bing_prices
        if not kept_detail.predict_prices and duplicate.predict_prices:
            kept_detail.predict_prices = duplicate.predict_prices
        
        # åˆå¹¶è¯„åˆ†å’Œè¯„è®º
        if not kept_detail.dianping_rating and duplicate.dianping_rating:
            kept_detail.dianping_rating = duplicate.dianping_rating
        if not kept_detail.meituan_rating and duplicate.meituan_rating:
            kept_detail.meituan_rating = duplicate.meituan_rating
        if not kept_detail.merged_rating and duplicate.merged_rating:
            kept_detail.merged_rating = duplicate.merged_rating
        
        if not kept_detail.dianping_reviews and duplicate.dianping_reviews:
            kept_detail.dianping_reviews = duplicate.dianping_reviews
        if not kept_detail.meituan_reviews and duplicate.meituan_reviews:
            kept_detail.meituan_reviews = duplicate.meituan_reviews
        
        # åˆå¹¶æè¿°ä¿¡æ¯
        if not kept_detail.merged_description and duplicate.merged_description:
            kept_detail.merged_description = duplicate.merged_description
        if not kept_detail.merged_facilities and duplicate.merged_facilities:
            kept_detail.merged_facilities = duplicate.merged_facilities
        if not kept_detail.merged_business_hours and duplicate.merged_business_hours:
            kept_detail.merged_business_hours = duplicate.merged_business_hours

def clean_duplicate_courts_with_merge():
    """æ¸…ç†é‡å¤åœºé¦†ï¼Œåˆå¹¶æœ‰æ•ˆæ•°æ®"""
    db = SessionLocal()
    
    try:
        # è·å–æ‰€æœ‰åœºé¦†
        all_courts = db.query(TennisCourt).all()
        
        print(f"ğŸ” å¼€å§‹æ¸…ç†é‡å¤åœºé¦†ï¼ˆåˆå¹¶æœ‰æ•ˆæ•°æ®ï¼‰\\n")
        print(f"æ¸…ç†å‰æ€»åœºé¦†æ•°: {len(all_courts)}")
        
        # æŒ‰åç§°åˆ†ç»„
        name_groups = defaultdict(list)
        for court in all_courts:
            name_groups[court.name].append(court)
        
        # æ‰¾å‡ºé‡å¤çš„åœºé¦†
        duplicates = {name: courts for name, courts in name_groups.items() if len(courts) > 1}
        
        print(f"æœ‰é‡å¤çš„åœºé¦†åç§°: {len(duplicates)}")
        
        # è®°å½•è¦åˆ é™¤çš„åœºé¦†ID
        to_delete_ids = []
        kept_courts = []
        
        for name, courts in duplicates.items():
            # æŒ‰IDæ’åºï¼Œä¿ç•™ç¬¬ä¸€ä¸ªï¼ˆIDæœ€å°çš„ï¼‰
            courts.sort(key=lambda x: x.id)
            kept_court = courts[0]
            duplicate_courts = courts[1:]
            
            print(f"\\nğŸŸï¸ {name}: ä¿ç•™ID {kept_court.id}, åˆ é™¤ {len(duplicate_courts)} ä¸ªé‡å¤è®°å½•")
            
            # åˆå¹¶åœºé¦†åŸºæœ¬ä¿¡æ¯
            merge_court_data(kept_court, duplicate_courts)
            
            # è·å–è¯¦æƒ…è®°å½•
            kept_detail = db.query(CourtDetail).filter(CourtDetail.court_id == kept_court.id).first()
            if not kept_detail:
                kept_detail = CourtDetail(court_id=kept_court.id)
                db.add(kept_detail)
            
            # è·å–é‡å¤åœºé¦†çš„è¯¦æƒ…è®°å½•
            duplicate_details = []
            for dup_court in duplicate_courts:
                dup_detail = db.query(CourtDetail).filter(CourtDetail.court_id == dup_court.id).first()
                if dup_detail:
                    duplicate_details.append(dup_detail)
            
            # åˆå¹¶è¯¦æƒ…æ•°æ®
            if duplicate_details:
                merge_detail_data(kept_detail, duplicate_details)
                print(f"   âœ… å·²åˆå¹¶ {len(duplicate_details)} ä¸ªè¯¦æƒ…è®°å½•çš„æœ‰æ•ˆæ•°æ®")
            
            kept_courts.append(kept_court)
            to_delete_ids.extend([court.id for court in duplicate_courts])
        
        print(f"\\nğŸ“Š æ¸…ç†ç»Ÿè®¡:")
        print(f"   è¦åˆ é™¤çš„é‡å¤åœºé¦†æ•°: {len(to_delete_ids)}")
        print(f"   è¦ä¿ç•™çš„åœºé¦†æ•°: {len(kept_courts)}")
        
        # ç¡®è®¤æ˜¯å¦æ‰§è¡Œåˆ é™¤
        confirm = input("\\nç¡®è®¤è¦åˆ é™¤è¿™äº›é‡å¤åœºé¦†å—ï¼Ÿ(y/N): ")
        if confirm.lower() != 'y':
            print("å–æ¶ˆåˆ é™¤æ“ä½œ")
            return
        
        # åˆ é™¤é‡å¤åœºé¦†çš„è¯¦æƒ…è®°å½•
        print("\\nğŸ—‘ï¸ åˆ é™¤é‡å¤åœºé¦†çš„è¯¦æƒ…è®°å½•...")
        deleted_details = db.query(CourtDetail).filter(CourtDetail.court_id.in_(to_delete_ids)).delete()
        print(f"   åˆ é™¤äº† {deleted_details} ä¸ªè¯¦æƒ…è®°å½•")
        
        # åˆ é™¤é‡å¤åœºé¦†
        print("ğŸ—‘ï¸ åˆ é™¤é‡å¤åœºé¦†...")
        deleted_courts = db.query(TennisCourt).filter(TennisCourt.id.in_(to_delete_ids)).delete()
        print(f"   åˆ é™¤äº† {deleted_courts} ä¸ªé‡å¤åœºé¦†")
        
        # æäº¤æ›´æ”¹
        db.commit()
        
        # éªŒè¯æ¸…ç†ç»“æœ
        remaining_courts = db.query(TennisCourt).all()
        print(f"\\nâœ… æ¸…ç†å®Œæˆ!")
        print(f"   æ¸…ç†åæ€»åœºé¦†æ•°: {len(remaining_courts)}")
        print(f"   å®é™…åˆ é™¤åœºé¦†æ•°: {len(all_courts) - len(remaining_courts)}")
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰é‡å¤
        remaining_names = [court.name for court in remaining_courts]
        unique_names = set(remaining_names)
        print(f"   å”¯ä¸€åœºé¦†åç§°æ•°: {len(unique_names)}")
        print(f"   æ˜¯å¦è¿˜æœ‰é‡å¤: {'æ˜¯' if len(remaining_names) != len(unique_names) else 'å¦'}")
        
    except Exception as e:
        print(f"âŒ æ¸…ç†å¤±è´¥: {e}")
        db.rollback()
    finally:
        db.close()

if __name__ == "__main__":
    clean_duplicate_courts_with_merge() 