#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½Googleæœç´¢è„šæœ¬
ä½¿ç”¨æ›´å¥½çš„åæ£€æµ‹ç­–ç•¥è®¿é—®Google
"""

import requests
import time
import random
from urllib.parse import quote
import json

class SmartGoogleSearcher:
    def __init__(self):
        self.proxies = {
            "http": "socks5h://127.0.0.1:7890",
            "https": "socks5h://127.0.0.1:7890"
        }
        
        # å¤šä¸ªUser-Agentè½®æ¢
        self.user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        ]
        
        # ä¼šè¯ä¿æŒ
        self.session = requests.Session()
        self.session.proxies = self.proxies
        
    def get_random_headers(self):
        """è·å–éšæœºè¯·æ±‚å¤´"""
        return {
            "User-Agent": random.choice(self.user_agents),
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8",
            "Accept-Language": "en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1",
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "none",
            "Cache-Control": "max-age=0"
        }
    
    def search_google(self, query, max_retries=3):
        """æœç´¢Google"""
        print(f"ğŸ” æœç´¢Google: {query}")
        
        for attempt in range(max_retries):
            try:
                # éšæœºå»¶è¿Ÿ
                time.sleep(random.uniform(1, 3))
                
                # æ„å»ºæœç´¢URL
                encoded_query = quote(query)
                search_url = f"https://www.google.com/search?q={encoded_query}&hl=en&num=10"
                
                # è·å–éšæœºè¯·æ±‚å¤´
                headers = self.get_random_headers()
                
                print(f"   å°è¯• {attempt + 1}/{max_retries}...")
                
                # å‘é€è¯·æ±‚
                response = self.session.get(
                    search_url, 
                    headers=headers, 
                    timeout=15,
                    allow_redirects=True
                )
                
                if response.status_code == 200:
                    print(f"âœ… æœç´¢æˆåŠŸ!")
                    print(f"   çŠ¶æ€ç : {response.status_code}")
                    print(f"   å†…å®¹é•¿åº¦: {len(response.text)} å­—ç¬¦")
                    
                    # åˆ†ææœç´¢ç»“æœ
                    return self.analyze_search_results(response.text, query)
                else:
                    print(f"âŒ çŠ¶æ€ç å¼‚å¸¸: {response.status_code}")
                    
            except requests.exceptions.ConnectionError as e:
                print(f"âŒ è¿æ¥é”™è¯¯ (å°è¯• {attempt + 1}): {e}")
                if "ConnectionResetError" in str(e):
                    print("   ğŸ’¡ Googleæ£€æµ‹åˆ°ä»£ç†ï¼Œå°è¯•æ›´æ¢ç­–ç•¥...")
                    time.sleep(random.uniform(2, 5))  # æ›´é•¿å»¶è¿Ÿ
            except requests.exceptions.Timeout as e:
                print(f"âŒ è¶…æ—¶é”™è¯¯ (å°è¯• {attempt + 1}): {e}")
            except Exception as e:
                print(f"âŒ æœªçŸ¥é”™è¯¯ (å°è¯• {attempt + 1}): {e}")
            
            # é‡è¯•å‰ç­‰å¾…
            if attempt < max_retries - 1:
                wait_time = random.uniform(3, 8)
                print(f"   ç­‰å¾… {wait_time:.1f} ç§’åé‡è¯•...")
                time.sleep(wait_time)
        
        print(f"âŒ æ‰€æœ‰å°è¯•éƒ½å¤±è´¥äº†")
        return None
    
    def analyze_search_results(self, html_content, query):
        """åˆ†ææœç´¢ç»“æœ"""
        print(f"\nğŸ“Š åˆ†ææœç´¢ç»“æœ...")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æœç´¢å…³é”®è¯
        query_keywords = query.lower().split()
        found_keywords = []
        for keyword in query_keywords:
            if keyword in html_content.lower():
                found_keywords.append(keyword)
        
        print(f"   å…³é”®è¯åŒ¹é…: {len(found_keywords)}/{len(query_keywords)}")
        if found_keywords:
            print(f"   åŒ¹é…çš„å…³é”®è¯: {', '.join(found_keywords)}")
        
        # æ£€æŸ¥ä»·æ ¼ä¿¡æ¯
        price_keywords = ["ä»·æ ¼", "æ”¶è´¹", "å…ƒ", "ï¿¥", "price", "cost", "RMB", "Â¥", "hour", "å°æ—¶"]
        price_info = []
        
        # ç®€å•çš„ä»·æ ¼ä¿¡æ¯æå–
        lines = html_content.split('\n')
        for line in lines:
            line_lower = line.lower()
            if any(keyword in line_lower for keyword in price_keywords):
                # æ¸…ç†HTMLæ ‡ç­¾
                clean_line = self.clean_html(line)
                if clean_line and len(clean_line) > 10:
                    price_info.append(clean_line[:200])
                    if len(price_info) >= 5:  # æœ€å¤šæ˜¾ç¤º5ä¸ª
                        break
        
        if price_info:
            print(f"   âœ… å‘ç°ä»·æ ¼ç›¸å…³ä¿¡æ¯ ({len(price_info)} æ¡):")
            for i, info in enumerate(price_info, 1):
                print(f"      {i}. {info}")
        else:
            print(f"   âš ï¸  æœªå‘ç°æ˜æ˜¾çš„ä»·æ ¼ä¿¡æ¯")
        
        # æ£€æŸ¥æ˜¯å¦è¢«é‡å®šå‘åˆ°éªŒè¯é¡µé¢
        if "recaptcha" in html_content.lower() or "verify" in html_content.lower():
            print(f"   âš ï¸  å¯èƒ½è¢«é‡å®šå‘åˆ°éªŒè¯é¡µé¢")
        
        return {
            "success": True,
            "content_length": len(html_content),
            "keyword_match": len(found_keywords),
            "price_info_count": len(price_info),
            "price_info": price_info,
            "has_recaptcha": "recaptcha" in html_content.lower()
        }
    
    def clean_html(self, text):
        """ç®€å•æ¸…ç†HTMLæ ‡ç­¾"""
        import re
        # ç§»é™¤HTMLæ ‡ç­¾
        clean = re.compile('<.*?>')
        text = re.sub(clean, '', text)
        # ç§»é™¤å¤šä½™ç©ºç™½
        text = ' '.join(text.split())
        return text
    
    def test_bing_search(self, query):
        """æµ‹è¯•Bingæœç´¢ä½œä¸ºå¯¹æ¯”"""
        print(f"\nğŸ” å¯¹æ¯”æµ‹è¯•Bingæœç´¢: {query}")
        
        try:
            encoded_query = quote(query)
            search_url = f"https://www.bing.com/search?q={encoded_query}"
            
            headers = self.get_random_headers()
            
            response = self.session.get(search_url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                print(f"âœ… Bingæœç´¢æˆåŠŸ!")
                print(f"   çŠ¶æ€ç : {response.status_code}")
                print(f"   å†…å®¹é•¿åº¦: {len(response.text)} å­—ç¬¦")
                
                # åˆ†æBingç»“æœ
                return self.analyze_search_results(response.text, query)
            else:
                print(f"âŒ Bingæœç´¢å¤±è´¥: {response.status_code}")
                
        except Exception as e:
            print(f"âŒ Bingæœç´¢å¼‚å¸¸: {e}")
        
        return None

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¾ æ™ºèƒ½Googleæœç´¢å·¥å…·")
    print("=" * 50)
    print("ä½¿ç”¨åæ£€æµ‹ç­–ç•¥è®¿é—®Googleæœç´¢")
    print("=" * 50)
    
    searcher = SmartGoogleSearcher()
    
    # æµ‹è¯•æœç´¢
    test_queries = [
        "æœé˜³å…¬å›­ç½‘çƒåœº ä»·æ ¼ 2024",
        "åŒ—äº¬ç½‘çƒåœºä»·æ ¼",
        "tennis court price beijing"
    ]
    
    results = {}
    
    for query in test_queries:
        print(f"\n{'='*60}")
        print(f"ğŸ” æµ‹è¯•æœç´¢: {query}")
        print(f"{'='*60}")
        
        # Googleæœç´¢
        google_result = searcher.search_google(query)
        results[f"google_{query}"] = google_result
        
        # Bingæœç´¢å¯¹æ¯”
        bing_result = searcher.test_bing_search(query)
        results[f"bing_{query}"] = bing_result
        
        # æœç´¢é—´éš”
        time.sleep(random.uniform(2, 5))
    
    # æ€»ç»“æŠ¥å‘Š
    print(f"\n{'='*60}")
    print("ğŸ“Š æœç´¢æµ‹è¯•æ€»ç»“")
    print(f"{'='*60}")
    
    google_success = sum(1 for key, result in results.items() 
                        if key.startswith("google") and result and result.get("success"))
    bing_success = sum(1 for key, result in results.items() 
                      if key.startswith("bing") and result and result.get("success"))
    
    print(f"Googleæœç´¢æˆåŠŸç‡: {google_success}/{len(test_queries)} ({google_success/len(test_queries)*100:.1f}%)")
    print(f"Bingæœç´¢æˆåŠŸç‡: {bing_success}/{len(test_queries)} ({bing_success/len(test_queries)*100:.1f}%)")
    
    # ä»·æ ¼ä¿¡æ¯ç»Ÿè®¡
    total_price_info = 0
    for key, result in results.items():
        if result and result.get("price_info_count"):
            total_price_info += result["price_info_count"]
    
    print(f"å‘ç°ä»·æ ¼ä¿¡æ¯æ€»æ•°: {total_price_info}")
    
    # å»ºè®®
    print(f"\nğŸ’¡ å»ºè®®:")
    if google_success > 0:
        print("âœ… Googleæœç´¢éƒ¨åˆ†æˆåŠŸï¼Œå¯ä»¥å°è¯•æ›´å¤šåæ£€æµ‹ç­–ç•¥")
    else:
        print("âŒ Googleæœç´¢å®Œå…¨å¤±è´¥ï¼Œå»ºè®®ä½¿ç”¨Bingæˆ–å…¶ä»–æœç´¢å¼•æ“")
    
    if bing_success > 0:
        print("âœ… Bingæœç´¢å¯ç”¨ï¼Œå¯ä»¥ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ")
    
    if total_price_info > 0:
        print("âœ… å‘ç°ä»·æ ¼ä¿¡æ¯ï¼Œå¯ä»¥ç”¨äºæ•°æ®æŠ“å–")
    else:
        print("âš ï¸  æœªå‘ç°ä»·æ ¼ä¿¡æ¯ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´æœç´¢å…³é”®è¯")

if __name__ == "__main__":
    main() 