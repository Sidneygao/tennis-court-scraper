#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Selenium Googleçˆ¬å–æµ‹è¯•è„šæœ¬
ä¸“é—¨æµ‹è¯•Googleæœç´¢åŠŸèƒ½ï¼Œæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨è¡Œä¸º
"""

import time
import json
import random
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, WebDriverException
from urllib.parse import quote

class GoogleSeleniumCrawler:
    """Google Seleniumçˆ¬è™«ç±»"""
    
    def __init__(self, use_proxy=True):
        self.use_proxy = use_proxy
        self.driver = None
        self.wait = None
        
    def setup_driver(self):
        """è®¾ç½®Chromeæµè§ˆå™¨é©±åŠ¨"""
        print("ğŸ”§ è®¾ç½®Chromeæµè§ˆå™¨é©±åŠ¨...")
        
        chrome_options = Options()
        
        # åŸºæœ¬è®¾ç½®
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--window-size=1920,1080")
        
        # æ¨¡æ‹ŸçœŸå®æµè§ˆå™¨
        chrome_options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
        
        # ç¦ç”¨è‡ªåŠ¨åŒ–æ£€æµ‹
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        
        # ä»£ç†è®¾ç½®
        if self.use_proxy:
            chrome_options.add_argument("--proxy-server=socks5://127.0.0.1:7890")
            print("   âœ… å·²å¯ç”¨ä»£ç†è®¾ç½® (socks5://127.0.0.1:7890)")
        else:
            print("   âš ï¸  æœªå¯ç”¨ä»£ç†è®¾ç½®")
        
        # ç¦ç”¨å›¾ç‰‡å’ŒCSSåŠ è½½ä»¥æé«˜é€Ÿåº¦
        prefs = {
            "profile.managed_default_content_settings.images": 2,
            "profile.default_content_setting_values.notifications": 2,
            "profile.managed_default_content_settings.stylesheets": 2
        }
        chrome_options.add_experimental_option("prefs", prefs)
        
        try:
            self.driver = webdriver.Chrome(options=chrome_options)
            self.wait = WebDriverWait(self.driver, 15)
            
            # æ‰§è¡ŒJavaScriptæ¥éšè—è‡ªåŠ¨åŒ–ç‰¹å¾
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            
            print("   âœ… Chromeé©±åŠ¨è®¾ç½®å®Œæˆ")
            return True
            
        except Exception as e:
            print(f"   âŒ Chromeé©±åŠ¨è®¾ç½®å¤±è´¥: {e}")
            return False
    
    def simulate_human_behavior(self):
        """æ¨¡æ‹Ÿäººç±»è¡Œä¸º"""
        # éšæœºæ»šåŠ¨
        scroll_amount = random.randint(300, 800)
        self.driver.execute_script(f"window.scrollBy(0, {scroll_amount});")
        time.sleep(random.uniform(0.5, 1.5))
        
        # éšæœºç§»åŠ¨é¼ æ ‡ï¼ˆæ¨¡æ‹Ÿï¼‰
        time.sleep(random.uniform(0.3, 0.8))
    
    def test_google_access(self):
        """æµ‹è¯•Googleè®¿é—®"""
        print("\nğŸ” æµ‹è¯•Googleä¸»é¡µè®¿é—®...")
        print("=" * 50)
        
        try:
            start_time = time.time()
            self.driver.get("https://www.google.com")
            end_time = time.time()
            
            load_time = round((end_time - start_time) * 1000, 2)
            current_url = self.driver.current_url
            page_title = self.driver.title
            
            print(f"âœ… Googleä¸»é¡µè®¿é—®æˆåŠŸ!")
            print(f"   åŠ è½½æ—¶é—´: {load_time}ms")
            print(f"   å½“å‰URL: {current_url}")
            print(f"   é¡µé¢æ ‡é¢˜: {page_title}")
            
            # æ£€æŸ¥é¡µé¢å†…å®¹
            page_source = self.driver.page_source.lower()
            if "google" in page_source:
                print(f"   âœ… ç¡®è®¤æ˜¯Googleé¡µé¢")
            else:
                print(f"   âš ï¸  å¯èƒ½ä¸æ˜¯Googleé¡µé¢")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰éªŒè¯ç 
            captcha_elements = self.driver.find_elements(By.CSS_SELECTOR, "form#captcha-form, .g-recaptcha, .recaptcha")
            if captcha_elements:
                print(f"   âš ï¸  æ£€æµ‹åˆ°éªŒè¯ç !")
                return {"status": "captcha_detected"}
            
            # æ£€æŸ¥æ˜¯å¦æœ‰åçˆ¬æç¤º
            anti_bot_keywords = ["unusual traffic", "automated requests", "robot", "bot", "suspicious"]
            found_anti_bot = []
            for keyword in anti_bot_keywords:
                if keyword in page_source:
                    found_anti_bot.append(keyword)
            
            if found_anti_bot:
                print(f"   âš ï¸  æ£€æµ‹åˆ°åçˆ¬å…³é”®è¯: {found_anti_bot}")
                return {"status": "anti_bot_detected", "keywords": found_anti_bot}
            
            print(f"   âœ… æœªæ£€æµ‹åˆ°æ˜æ˜¾çš„åçˆ¬æç¤º")
            return {
                "status": "success",
                "load_time": load_time,
                "url": current_url,
                "title": page_title
            }
            
        except Exception as e:
            print(f"âŒ Googleä¸»é¡µè®¿é—®å¤±è´¥: {e}")
            return {"status": "error", "error": str(e)}
    
    def search_google(self, query):
        """Googleæœç´¢"""
        print(f"\nğŸ” æ‰§è¡ŒGoogleæœç´¢: {query}")
        print("=" * 50)
        
        try:
            # ç­‰å¾…æœç´¢æ¡†å‡ºç°
            search_box = self.wait.until(EC.presence_of_element_located((By.NAME, "q")))
            
            # æ¨¡æ‹Ÿäººç±»è¾“å…¥è¡Œä¸º
            search_box.clear()
            for char in query:
                search_box.send_keys(char)
                time.sleep(random.uniform(0.05, 0.15))
            
            # çŸ­æš‚åœé¡¿
            time.sleep(random.uniform(0.5, 1.0))
            
            # æŒ‰å›è½¦é”®æœç´¢
            search_box.send_keys(Keys.RETURN)
            
            # ç­‰å¾…æœç´¢ç»“æœåŠ è½½
            self.wait.until(EC.presence_of_element_located((By.ID, "search")))
            
            # æ¨¡æ‹Ÿäººç±»æµè§ˆè¡Œä¸º
            self.simulate_human_behavior()
            
            # è·å–æœç´¢ç»“æœ
            search_results = self.driver.find_elements(By.CSS_SELECTOR, "div.g")
            
            print(f"âœ… Googleæœç´¢æˆåŠŸ!")
            print(f"   å½“å‰URL: {self.driver.current_url}")
            print(f"   é¡µé¢æ ‡é¢˜: {self.driver.title}")
            print(f"   æœç´¢ç»“æœæ•°é‡: {len(search_results)}")
            
            # åˆ†ææœç´¢ç»“æœ
            results_data = []
            if search_results:
                print(f"   ğŸ“‹ å‰5ä¸ªæœç´¢ç»“æœ:")
                for i, result in enumerate(search_results[:5], 1):
                    try:
                        title_element = result.find_element(By.CSS_SELECTOR, "h3")
                        title = title_element.text
                        
                        # å°è¯•è·å–é“¾æ¥
                        try:
                            link_element = result.find_element(By.CSS_SELECTOR, "a")
                            link = link_element.get_attribute("href")
                        except:
                            link = "æ— é“¾æ¥"
                        
                        # å°è¯•è·å–æ‘˜è¦
                        try:
                            snippet_element = result.find_element(By.CSS_SELECTOR, "div.VwiC3b")
                            snippet = snippet_element.text
                        except:
                            snippet = "æ— æ‘˜è¦"
                        
                        print(f"      {i}. {title}")
                        print(f"         URL: {link}")
                        print(f"         æ‘˜è¦: {snippet[:100]}...")
                        
                        results_data.append({
                            "title": title,
                            "url": link,
                            "snippet": snippet
                        })
                        
                    except Exception as e:
                        print(f"      {i}. [æ— æ³•è·å–æ ‡é¢˜: {e}]")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æœç´¢å…³é”®è¯
            page_source = self.driver.page_source
            query_words = query.split()
            found_keywords = [word for word in query_words if word in page_source]
            
            if found_keywords:
                print(f"   âœ… æœç´¢ç»“æœåŒ…å«å…³é”®è¯: {found_keywords}")
            else:
                print(f"   âš ï¸  æœç´¢ç»“æœå¯èƒ½ä¸ç›¸å…³")
            
            return {
                "status": "success",
                "url": self.driver.current_url,
                "title": self.driver.title,
                "results_count": len(search_results),
                "results": results_data,
                "found_keywords": found_keywords
            }
            
        except TimeoutException:
            print(f"âŒ æœç´¢è¶…æ—¶")
            return {"status": "timeout", "error": "æœç´¢è¶…æ—¶"}
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
            return {"status": "error", "error": str(e)}
    
    def search_tennis_court_prices(self):
        """æœç´¢ç½‘çƒåœºä»·æ ¼ä¿¡æ¯"""
        search_queries = [
            "æœé˜³å…¬å›­ç½‘çƒåœº ä»·æ ¼ 2024",
            "åŒ—äº¬ç½‘çƒåœºä»·æ ¼",
            "é‡‘åœ°ç½‘çƒä»·æ ¼",
            "å˜‰é‡Œä¸­å¿ƒç½‘çƒåœºä»·æ ¼"
        ]
        
        all_results = {}
        
        for query in search_queries:
            print(f"\nğŸ¾ æœç´¢ç½‘çƒåœºä»·æ ¼: {query}")
            
            # å…ˆè®¿é—®Googleä¸»é¡µ
            homepage_result = self.test_google_access()
            if homepage_result.get("status") != "success":
                print(f"âŒ æ— æ³•è®¿é—®Googleä¸»é¡µï¼Œè·³è¿‡æœç´¢: {query}")
                all_results[query] = {"status": "homepage_failed", "result": homepage_result}
                continue
            
            # æ‰§è¡Œæœç´¢
            search_result = self.search_google(query)
            all_results[query] = search_result
            
            # éšæœºç­‰å¾…ï¼Œé¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(random.uniform(2, 4))
        
        return all_results
    
    def close(self):
        """å…³é—­æµè§ˆå™¨"""
        if self.driver:
            self.driver.quit()
            print("âœ… æµè§ˆå™¨å·²å…³é—­")
    
    def save_results(self, results, filename="selenium_google_results.json"):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        print(f"\nğŸ’¾ ä¿å­˜æµ‹è¯•ç»“æœåˆ° {filename}...")
        
        test_report = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "test_type": "Selenium Googleçˆ¬å–æµ‹è¯•",
            "use_proxy": self.use_proxy,
            "results": results
        }
        
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(test_report, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… æµ‹è¯•ç»“æœå·²ä¿å­˜")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¾ Selenium Googleçˆ¬å–æµ‹è¯•å·¥å…·")
    print("=" * 50)
    print("ä¸“é—¨æµ‹è¯•Googleæœç´¢åŠŸèƒ½ï¼Œæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨è¡Œä¸º")
    print("=" * 50)
    
    # æµ‹è¯•1: ä½¿ç”¨ä»£ç†
    print("\nğŸ“‹ æµ‹è¯•1: ä½¿ç”¨ä»£ç†è®¿é—®Google")
    crawler1 = GoogleSeleniumCrawler(use_proxy=True)
    
    if crawler1.setup_driver():
        try:
            # æµ‹è¯•Googleè®¿é—®
            homepage_result = crawler1.test_google_access()
            
            if homepage_result.get("status") == "success":
                # æµ‹è¯•ç½‘çƒåœºä»·æ ¼æœç´¢
                search_results = crawler1.search_tennis_court_prices()
                crawler1.save_results(search_results, "selenium_google_proxy_results.json")
            else:
                print(f"âŒ Googleè®¿é—®å¤±è´¥: {homepage_result}")
                crawler1.save_results({"homepage": homepage_result}, "selenium_google_proxy_failed.json")
        finally:
            crawler1.close()
    
    # æµ‹è¯•2: ä¸ä½¿ç”¨ä»£ç†
    print("\nğŸ“‹ æµ‹è¯•2: ä¸ä½¿ç”¨ä»£ç†è®¿é—®Google")
    crawler2 = GoogleSeleniumCrawler(use_proxy=False)
    
    if crawler2.setup_driver():
        try:
            # æµ‹è¯•Googleè®¿é—®
            homepage_result = crawler2.test_google_access()
            
            if homepage_result.get("status") == "success":
                # æµ‹è¯•ç½‘çƒåœºä»·æ ¼æœç´¢
                search_results = crawler2.search_tennis_court_prices()
                crawler2.save_results(search_results, "selenium_google_no_proxy_results.json")
            else:
                print(f"âŒ Googleè®¿é—®å¤±è´¥: {homepage_result}")
                crawler2.save_results({"homepage": homepage_result}, "selenium_google_no_proxy_failed.json")
        finally:
            crawler2.close()
    
    print("\nğŸ“Š æµ‹è¯•å®Œæˆ")
    print("=" * 50)
    print("è¯·æŸ¥çœ‹ç”Ÿæˆçš„æµ‹è¯•ç»“æœæ–‡ä»¶äº†è§£è¯¦ç»†ä¿¡æ¯")

if __name__ == "__main__":
    main() 