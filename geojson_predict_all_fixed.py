#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é‡æ–°æ‰§è¡ŒGeoJSON+2KMæ­¥è¿›æ³•é¢„æµ‹ä»·æ ¼ - ä½¿ç”¨æ­£ç¡®çš„ç»çº¬åº¦æ•°æ®
"""
import sqlite3
import json
import math
from datetime import datetime
from app.scrapers.price_predictor import PricePredictor
from app.database import get_db
from app.models import TennisCourt, CourtDetail

def calculate_distance(lat1, lng1, lat2, lng2):
    """è®¡ç®—ä¸¤ç‚¹é—´è·ç¦»ï¼ˆå…¬é‡Œï¼‰"""
    R = 6371  # åœ°çƒåŠå¾„ï¼ˆå…¬é‡Œï¼‰
    
    lat1_rad = math.radians(lat1)
    lng1_rad = math.radians(lng1)
    lat2_rad = math.radians(lat2)
    lng2_rad = math.radians(lng2)
    
    dlat = lat2_rad - lat1_rad
    dlng = lng2_rad - lng1_rad
    
    a = math.sin(dlat/2)**2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlng/2)**2
    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))
    
    return R * c

def get_nearby_courts_with_real_prices(cursor, target_lat, target_lng, max_distance=16.0):
    """è·å–æŒ‡å®šè·ç¦»å†…æœ‰çœŸå®ä»·æ ¼çš„åœºé¦†"""
    cursor.execute("""
        SELECT tc.id, tc.name, tc.latitude, tc.longitude, tc.court_type, cd.merged_prices
        FROM tennis_courts tc
        LEFT JOIN court_details cd ON tc.id = cd.court_id
        WHERE cd.merged_prices IS NOT NULL 
        AND cd.merged_prices != '[]'
        AND cd.merged_prices != 'null'
    """)
    
    courts_with_prices = cursor.fetchall()
    nearby_courts = []
    
    for court_id, name, lat, lng, court_type, merged_prices in courts_with_prices:
        distance = calculate_distance(target_lat, target_lng, lat, lng)
        
        if distance <= max_distance:
            try:
                prices = json.loads(merged_prices) if merged_prices else []
                if prices:
                    nearby_courts.append({
                        'id': court_id,
                        'name': name,
                        'latitude': lat,
                        'longitude': lng,
                        'court_type': court_type,
                        'distance': distance,
                        'prices': prices
                    })
            except:
                continue
    
    return sorted(nearby_courts, key=lambda x: x['distance'])

def main():
    print("ğŸ” é‡æ–°æ‰§è¡ŒGeoJSON+2KMæ­¥è¿›æ³•é¢„æµ‹ä»·æ ¼...")
    print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # 1. åˆå§‹åŒ–æ•°æ®åº“è¿æ¥å’Œé¢„æµ‹å™¨
    db = next(get_db())
    predictor = PricePredictor()
    
    # 2. ç»Ÿè®¡æœ‰çœŸå®ä»·æ ¼çš„åœºé¦†
    courts_with_real_prices = db.query(TennisCourt).join(
        CourtDetail, CourtDetail.court_id == TennisCourt.id
    ).filter(
        CourtDetail.merged_prices.isnot(None),
        CourtDetail.merged_prices != '[]',
        CourtDetail.merged_prices != 'null'
    ).count()
    
    print(f"ğŸ“Š æœ‰çœŸå®ä»·æ ¼çš„åœºé¦†æ•°: {courts_with_real_prices}")
    
    # 3. è·å–æ‰€æœ‰éœ€è¦é¢„æµ‹çš„åœºé¦†
    all_courts = db.query(TennisCourt).all()
    print(f"ğŸ“Š æ€»åœºé¦†æ•°: {len(all_courts)}")
    
    # 4. æ‰§è¡Œé¢„æµ‹
    results = []
    success_count = 0
    no_reference_count = 0
    
    for court in all_courts:
        print(f"\nğŸ” å¼€å§‹åˆ†æåœºé¦†: {court.name}")
        
        try:
            # ä½¿ç”¨ç°æœ‰çš„é¢„æµ‹æ–¹æ³•
            prediction = predictor.predict_price_for_court(court)
            
            if prediction:
                # æ›´æ–°æ•°æ®åº“
                detail = db.query(CourtDetail).filter(CourtDetail.court_id == court.id).first()
                if not detail:
                    detail = CourtDetail(court_id=court.id)
                    db.add(detail)
                    db.commit()
                    db.refresh(detail)
                
                detail.predict_prices = json.dumps(prediction, ensure_ascii=False)
                db.commit()
                
                print(f"  âœ… é¢„æµ‹æˆåŠŸ: {prediction}")
                success_count += 1
                
                results.append({
                    'court_id': court.id,
                    'name': court.name,
                    'prediction': prediction,
                    'search_radius': prediction.get('search_radius', 'unknown'),
                    'data_count': prediction.get('data_count', 0)
                })
            else:
                print(f"  âŒ é¢„æµ‹å¤±è´¥")
                no_reference_count += 1
                
        except Exception as e:
            print(f"  âŒ é¢„æµ‹å¼‚å¸¸: {str(e)}")
            no_reference_count += 1
    
    # 5. ç»Ÿè®¡ç»“æœ
    print(f"\nğŸ“Š é¢„æµ‹ç»“æœç»Ÿè®¡:")
    print(f"  æ€»åœºé¦†æ•°: {len(all_courts)}")
    print(f"  é¢„æµ‹æˆåŠŸ: {success_count} ä¸ª")
    print(f"  æ— å‚è€ƒæ•°æ®: {no_reference_count} ä¸ª")
    print(f"  æˆåŠŸç‡: {success_count/len(all_courts)*100:.1f}%")
    
    # 6. ä¿å­˜è¯¦ç»†ç»“æœ
    result_file = f"geojson_predict_results_fixed_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump({
            'timestamp': datetime.now().isoformat(),
            'summary': {
                'total_courts': len(all_courts),
                'success_count': success_count,
                'no_reference_count': no_reference_count,
                'success_rate': success_count/len(all_courts)*100
            },
            'results': results
        }, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
    print(f"â° ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    db.close()

if __name__ == "__main__":
    main() 