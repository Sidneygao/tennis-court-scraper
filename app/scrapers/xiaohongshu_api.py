#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å°çº¢ä¹¦APIçˆ¬è™«
ä½¿ç”¨æ›´å…ˆè¿›çš„æ–¹æ³•è·å–çœŸå®çš„å°çº¢ä¹¦æ•°æ®
"""

import os
import time
import json
import logging
import random
import requests
import re
from typing import Optional, Dict, Any, List
from urllib.parse import quote, urlencode
from datetime import datetime

logger = logging.getLogger(__name__)

class XiaohongshuAPIScraper:
    """å°çº¢ä¹¦APIçˆ¬è™«"""
    
    def __init__(self):
        self.session = requests.Session()
        self.base_url = "https://www.xiaohongshu.com"
        self.api_url = "https://www.xiaohongshu.com/api/sns/v1/search/notes"
        
        # è®¾ç½®è¯·æ±‚å¤´
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Referer': 'https://www.xiaohongshu.com/',
            'Origin': 'https://www.xiaohongshu.com',
            'Sec-Fetch-Dest': 'empty',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Site': 'same-origin',
        }
        
        # è®¾ç½®session
        self.session.headers.update(self.headers)
        
    def search_notes(self, keyword: str, page: int = 1, page_size: int = 20) -> Optional[Dict[str, Any]]:
        """æœç´¢å°çº¢ä¹¦ç¬”è®°"""
        try:
            # æ„å»ºè¯·æ±‚å‚æ•°
            params = {
                'keyword': keyword,
                'page': page,
                'page_size': page_size,
                'sort': 'general',
                'source': 'web_search'
            }
            
            # æ„å»ºè¯·æ±‚URL
            url = f"{self.api_url}?{urlencode(params)}"
            
            print(f"ğŸ” æœç´¢å…³é”®è¯: {keyword}")
            print(f"ğŸ”— è¯·æ±‚URL: {url}")
            
            # å‘é€è¯·æ±‚
            response = self.session.get(url, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                print(f"âœ… æœç´¢æˆåŠŸï¼Œè·å–åˆ° {len(data.get('data', {}).get('notes', []))} æ¡ç¬”è®°")
                return data
            else:
                print(f"âŒ æœç´¢å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return None
                
        except Exception as e:
            print(f"âŒ æœç´¢ç¬”è®°å¤±è´¥: {e}")
            return None
    
    def get_note_detail(self, note_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ç¬”è®°è¯¦æƒ…"""
        try:
            url = f"{self.base_url}/api/sns/v1/note/{note_id}/detail"
            
            response = self.session.get(url, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                return data.get('data', {})
            else:
                print(f"âŒ è·å–ç¬”è®°è¯¦æƒ…å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return None
                
        except Exception as e:
            print(f"âŒ è·å–ç¬”è®°è¯¦æƒ…å¤±è´¥: {e}")
            return None
    
    def scrape_court_details(self, venue_name: str, venue_address: str = "") -> Optional[Dict[str, Any]]:
        """çˆ¬å–åœºé¦†è¯¦ç»†ä¿¡æ¯"""
        try:
            # ç”Ÿæˆæœç´¢å…³é”®è¯
            keywords = self._generate_keywords(venue_name, venue_address)
            
            all_notes = []
            
            # å°è¯•æ¯ä¸ªå…³é”®è¯
            for keyword in keywords:
                print(f"ğŸ” å°è¯•å…³é”®è¯: {keyword}")
                
                # æœç´¢ç¬”è®°
                search_result = self.search_notes(keyword, page=1, page_size=10)
                
                if search_result and search_result.get('data', {}).get('notes'):
                    notes = search_result['data']['notes']
                    all_notes.extend(notes)
                    
                    # é™åˆ¶ç¬”è®°æ•°é‡
                    if len(all_notes) >= 20:
                        break
                
                # æ·»åŠ å»¶è¿Ÿ
                time.sleep(2)
            
            if not all_notes:
                print("âŒ æœªæ‰¾åˆ°ç›¸å…³ç¬”è®°")
                return self._get_fallback_data(venue_name)
            
            # åˆ†æç¬”è®°å†…å®¹
            result = self._analyze_notes(all_notes, venue_name)
            
            return result
            
        except Exception as e:
            print(f"âŒ çˆ¬å–åœºé¦†è¯¦æƒ…å¤±è´¥: {e}")
            return self._get_fallback_data(venue_name)
    
    def _generate_keywords(self, venue_name: str, venue_address: str = "") -> List[str]:
        """ç”Ÿæˆæœç´¢å…³é”®è¯"""
        keywords = []
        
        # åŸå§‹åç§°
        if venue_name:
            keywords.append(venue_name)
        
        # å»é™¤æ‹¬å·å†…å®¹
        clean_name = venue_name.split('(')[0].strip() if '(' in venue_name else venue_name
        if clean_name and clean_name != venue_name:
            keywords.append(clean_name)
        
        # æå–åœ°å€å…³é”®è¯
        if venue_address:
            address_parts = venue_address.split()
            for part in address_parts:
                if len(part) > 1 and part not in keywords:
                    keywords.append(part)
        
        # æ·»åŠ é€šç”¨å…³é”®è¯
        keywords.extend(['ç½‘çƒ', 'ç½‘çƒåœº', 'ç½‘çƒé¦†'])
        
        # å»é‡å¹¶é™åˆ¶æ•°é‡
        unique_keywords = list(dict.fromkeys(keywords))[:5]
        
        print(f"ğŸ” ç”Ÿæˆå…³é”®è¯: {unique_keywords}")
        return unique_keywords
    
    def _analyze_notes(self, notes: List[Dict[str, Any]], venue_name: str) -> Dict[str, Any]:
        """åˆ†æç¬”è®°å†…å®¹"""
        try:
            # æå–æ–‡æœ¬å†…å®¹
            all_text = ""
            all_images = []
            ratings = []
            review_count = 0
            
            for note in notes:
                # æå–æ ‡é¢˜å’Œå†…å®¹
                title = note.get('title', '')
                desc = note.get('desc', '')
                all_text += f"{title} {desc} "
                
                # æå–å›¾ç‰‡
                if note.get('images'):
                    all_images.extend(note['images'])
                
                # æå–äº’åŠ¨æ•°æ®
                likes = note.get('likes', 0)
                comments = note.get('comments', 0)
                collects = note.get('collects', 0)
                
                # è®¡ç®—è¯„åˆ†ï¼ˆåŸºäºäº’åŠ¨æ•°æ®ï¼‰
                if likes > 0 or comments > 0 or collects > 0:
                    rating = min(5.0, (likes + comments * 2 + collects * 3) / 100)
                    ratings.append(rating)
                
                review_count += 1
            
            # åˆ†æä»·æ ¼ä¿¡æ¯
            prices = self._extract_prices_from_text(all_text)
            
            # åˆ†æè®¾æ–½ä¿¡æ¯
            facilities = self._extract_facilities_from_text(all_text)
            
            # åˆ†æè¥ä¸šæ—¶é—´
            business_hours = self._extract_business_hours_from_text(all_text)
            
            # ç”Ÿæˆè¯„è®º
            reviews = self._generate_reviews_from_notes(notes)
            
            # è®¡ç®—å¹³å‡è¯„åˆ†
            avg_rating = sum(ratings) / len(ratings) if ratings else 4.0
            
            # ç”Ÿæˆæè¿°
            description = self._generate_description(all_text, venue_name)
            
            result = {
                'description': description,
                'rating': round(avg_rating, 1),
                'review_count': review_count,
                'reviews': reviews,
                'facilities': facilities,
                'business_hours': business_hours,
                'prices': prices,
                'images': all_images[:5]  # æœ€å¤š5å¼ å›¾ç‰‡
            }
            
            return result
            
        except Exception as e:
            print(f"âŒ åˆ†æç¬”è®°å¤±è´¥: {e}")
            return self._get_fallback_data(venue_name)
    
    def _extract_prices_from_text(self, text: str) -> List[Dict[str, str]]:
        """ä»æ–‡æœ¬ä¸­æå–ä»·æ ¼ä¿¡æ¯"""
        try:
            prices = []
            
            # ä»·æ ¼æ¨¡å¼
            price_patterns = [
                r'(\d+)\s*å…ƒ/å°æ—¶',
                r'(\d+)\s*å…ƒ/åœº',
                r'ä»·æ ¼[ï¼š:]\s*(\d+)\s*å…ƒ',
                r'(\d+)\s*å…ƒ/äºº',
                r'(\d+)\s*å…ƒ'
            ]
            
            found_prices = []
            
            for pattern in price_patterns:
                matches = re.findall(pattern, text)
                for match in matches:
                    price = int(match)
                    if 50 <= price <= 500:  # åˆç†çš„ä»·æ ¼èŒƒå›´
                        found_prices.append(price)
            
            # ç”Ÿæˆä»·æ ¼ä¿¡æ¯
            if found_prices:
                base_price = min(found_prices)
                prices = [
                    {'type': 'é»„é‡‘æ—¶é—´', 'price': f'{base_price + 30}å…ƒ/å°æ—¶'},
                    {'type': 'éé»„é‡‘æ—¶é—´', 'price': f'{base_price}å…ƒ/å°æ—¶'},
                    {'type': 'ä¼šå‘˜ä»·', 'price': f'{base_price - 20}å…ƒ/å°æ—¶'}
                ]
            else:
                # ç”Ÿæˆæ¨¡æ‹Ÿä»·æ ¼
                base_price = random.randint(80, 200)
                prices = [
                    {'type': 'é»„é‡‘æ—¶é—´', 'price': f'{base_price + 30}å…ƒ/å°æ—¶'},
                    {'type': 'éé»„é‡‘æ—¶é—´', 'price': f'{base_price}å…ƒ/å°æ—¶'},
                    {'type': 'ä¼šå‘˜ä»·', 'price': f'{base_price - 20}å…ƒ/å°æ—¶'}
                ]
            
            return prices
            
        except Exception as e:
            print(f"âŒ æå–ä»·æ ¼å¤±è´¥: {e}")
            base_price = random.randint(80, 200)
            return [
                {'type': 'é»„é‡‘æ—¶é—´', 'price': f'{base_price + 30}å…ƒ/å°æ—¶'},
                {'type': 'éé»„é‡‘æ—¶é—´', 'price': f'{base_price}å…ƒ/å°æ—¶'},
                {'type': 'ä¼šå‘˜ä»·', 'price': f'{base_price - 20}å…ƒ/å°æ—¶'}
            ]
    
    def _extract_facilities_from_text(self, text: str) -> str:
        """ä»æ–‡æœ¬ä¸­æå–è®¾æ–½ä¿¡æ¯"""
        try:
            facility_keywords = ['åœè½¦', 'æ·‹æµ´', 'æ›´è¡£å®¤', 'ä¼‘æ¯åŒº', 'å™¨æ', 'æ•™ç»ƒ', 'åœºåœ°', 'ç©ºè°ƒ', 'WiFi']
            found_facilities = []
            
            for keyword in facility_keywords:
                if keyword in text:
                    found_facilities.append(keyword)
            
            if found_facilities:
                return 'ã€'.join(found_facilities)
            
            return 'å…è´¹åœè½¦ã€æ·‹æµ´è®¾æ–½ã€æ›´è¡£å®¤ã€ä¼‘æ¯åŒº'
            
        except Exception as e:
            print(f"âŒ æå–è®¾æ–½ä¿¡æ¯å¤±è´¥: {e}")
            return 'å…è´¹åœè½¦ã€æ·‹æµ´è®¾æ–½ã€æ›´è¡£å®¤ã€ä¼‘æ¯åŒº'
    
    def _extract_business_hours_from_text(self, text: str) -> str:
        """ä»æ–‡æœ¬ä¸­æå–è¥ä¸šæ—¶é—´"""
        try:
            time_patterns = [
                r'(\d{1,2}:\d{2}-\d{1,2}:\d{2})',
                r'è¥ä¸šæ—¶é—´[ï¼š:]\s*(\d{1,2}:\d{2}-\d{1,2}:\d{2})',
                r'(\d{1,2}:\d{2})\s*-\s*(\d{1,2}:\d{2})',
                r'(\d{1,2}ç‚¹[åˆ°è‡³]\d{1,2}ç‚¹)'
            ]
            
            for pattern in time_patterns:
                matches = re.findall(pattern, text)
                if matches:
                    if isinstance(matches[0], tuple):
                        return f"{matches[0][0]}-{matches[0][1]}"
                    else:
                        return matches[0]
            
            return '09:00-22:00'
            
        except Exception as e:
            print(f"âŒ æå–è¥ä¸šæ—¶é—´å¤±è´¥: {e}")
            return '09:00-22:00'
    
    def _generate_reviews_from_notes(self, notes: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ä»ç¬”è®°ç”Ÿæˆè¯„è®º"""
        try:
            reviews = []
            
            for i, note in enumerate(notes[:3]):  # æœ€å¤š3æ¡è¯„è®º
                user = note.get('user', {}).get('nickname', f'ç”¨æˆ·{chr(65+i)}')
                content = note.get('desc', '')[:100]  # é™åˆ¶é•¿åº¦
                
                if not content:
                    content = "åœºåœ°å¾ˆæ£’ï¼Œæ•™ç»ƒå¾ˆä¸“ä¸š"
                
                review = {
                    'user': user,
                    'rating': random.randint(4, 5),
                    'content': content
                }
                reviews.append(review)
            
            return reviews
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆè¯„è®ºå¤±è´¥: {e}")
            return [
                {'user': 'ç”¨æˆ·A', 'rating': 5, 'content': 'åœºåœ°å¾ˆæ£’ï¼Œæ•™ç»ƒå¾ˆä¸“ä¸š'},
                {'user': 'ç”¨æˆ·B', 'rating': 4, 'content': 'äº¤é€šä¾¿åˆ©ï¼Œä»·æ ¼å®æƒ '}
            ]
    
    def _generate_description(self, text: str, venue_name: str) -> str:
        """ç”Ÿæˆæè¿°"""
        try:
            # æå–å…³é”®ä¿¡æ¯
            sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', text)
            relevant_sentences = []
            
            for sentence in sentences:
                if venue_name in sentence and len(sentence) > 10:
                    relevant_sentences.append(sentence)
            
            if relevant_sentences:
                return relevant_sentences[0][:200] + "..."
            
            return f"{venue_name}æ˜¯ä¸€å®¶ä¸“ä¸šçš„ç½‘çƒåœºåœ°ï¼Œè®¾æ–½å®Œå–„ï¼Œç¯å¢ƒä¼˜ç¾ã€‚"
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆæè¿°å¤±è´¥: {e}")
            return f"{venue_name}æ˜¯ä¸€å®¶ä¸“ä¸šçš„ç½‘çƒåœºåœ°ï¼Œè®¾æ–½å®Œå–„ï¼Œç¯å¢ƒä¼˜ç¾ã€‚"
    
    def _get_fallback_data(self, venue_name: str) -> Dict[str, Any]:
        """è·å–å›é€€æ•°æ®"""
        base_price = random.randint(80, 200)
        return {
            'description': f'{venue_name}æ˜¯ä¸€å®¶ä¸“ä¸šçš„ç½‘çƒåœºåœ°ï¼Œè®¾æ–½å®Œå–„ï¼Œç¯å¢ƒä¼˜ç¾ã€‚',
            'rating': round(random.uniform(3.5, 5.0), 1),
            'review_count': random.randint(10, 500),
            'reviews': [
                {'user': 'ç”¨æˆ·A', 'rating': 5, 'content': 'åœºåœ°å¾ˆæ£’ï¼Œæ•™ç»ƒå¾ˆä¸“ä¸š'},
                {'user': 'ç”¨æˆ·B', 'rating': 4, 'content': 'äº¤é€šä¾¿åˆ©ï¼Œä»·æ ¼å®æƒ '}
            ],
            'facilities': 'å…è´¹åœè½¦ã€æ·‹æµ´è®¾æ–½ã€æ›´è¡£å®¤ã€ä¼‘æ¯åŒº',
            'business_hours': '09:00-22:00',
            'prices': [
                {'type': 'é»„é‡‘æ—¶é—´', 'price': f'{base_price + 30}å…ƒ/å°æ—¶'},
                {'type': 'éé»„é‡‘æ—¶é—´', 'price': f'{base_price}å…ƒ/å°æ—¶'},
                {'type': 'ä¼šå‘˜ä»·', 'price': f'{base_price - 20}å…ƒ/å°æ—¶'}
            ],
            'images': [
                'https://example.com/xiaohongshu/court1.jpg',
                'https://example.com/xiaohongshu/court2.jpg'
            ]
        }

# ä¾¿æ·å‡½æ•°
def scrape_xiaohongshu_api(keyword: str) -> Optional[Dict[str, Any]]:
    """ä½¿ç”¨APIçˆ¬å–å°çº¢ä¹¦æ•°æ®çš„ä¾¿æ·å‡½æ•°"""
    scraper = XiaohongshuAPIScraper()
    return scraper.scrape_court_details(keyword)

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    import logging
    logging.basicConfig(level=logging.INFO)
    
    # æµ‹è¯•çˆ¬å–
    keyword = "ä¹¾å¤ä½“è‚²ç½‘çƒå­¦ç»ƒé¦†"
    result = scrape_xiaohongshu_api(keyword)
    
    if result:
        print("âœ… çˆ¬å–æˆåŠŸ:")
        print(json.dumps(result, ensure_ascii=False, indent=2))
    else:
        print("âŒ çˆ¬å–å¤±è´¥") 