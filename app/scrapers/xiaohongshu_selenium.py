#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import time
import tempfile
import logging
import random
import re
from typing import Optional, Dict, Any, List
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup

logger = logging.getLogger(__name__)

class XiaohongshuSeleniumScraper:
    """å°çº¢ä¹¦Seleniumçˆ¬è™« - ä¿®å¤ç‰ˆæœ¬"""
    
    def __init__(self, user_data_dir: str = None):
        self.user_data_dir = user_data_dir
        self.driver = None
        self._temp_dir = None
    
    def setup_driver(self):
        """è®¾ç½®Chromeæµè§ˆå™¨é©±åŠ¨ - ä½¿ç”¨Profile 1"""
        try:
            chrome_options = Options()
            
            # åŸºæœ¬è®¾ç½®
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-blink-features=AutomationControlled')
            chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
            chrome_options.add_experimental_option('useAutomationExtension', False)
            
            # ä½¿ç”¨Profile 1 - ç®€åŒ–é…ç½®
            user_data_dir = os.path.expanduser("~/AppData/Local/Google/Chrome/User Data")
            user_data_dir = os.path.abspath(user_data_dir)
            profile_path = os.path.join(user_data_dir, "Profile 1")
            
            print(f"ğŸ” ä½¿ç”¨Profile 1: {profile_path}")
            
            # æ£€æŸ¥profileæ˜¯å¦å­˜åœ¨
            if not os.path.exists(profile_path):
                print(f"âŒ Profile 1ä¸å­˜åœ¨: {profile_path}")
                return None
            
            # è®¾ç½®Chromeé€‰é¡¹ - ä¸ä½¿ç”¨DevTools
            chrome_options.add_argument(f'--user-data-dir={user_data_dir}')
            chrome_options.add_argument('--profile-directory=Profile 1')
            
            # ç¦ç”¨ä¸å¿…è¦çš„åŠŸèƒ½
            chrome_options.add_argument('--disable-images')
            chrome_options.add_argument('--disable-javascript')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--disable-extensions')
            chrome_options.add_argument('--disable-plugins')
            
            # è®¾ç½®çª—å£å¤§å°
            chrome_options.add_argument('--window-size=1920,1080')
            
            # è®¾ç½®User-Agent
            chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
            
            # åˆ›å»ºChromeé©±åŠ¨
            service = Service(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service, options=chrome_options)
            
            # è®¾ç½®é¡µé¢åŠ è½½è¶…æ—¶
            driver.set_page_load_timeout(30)
            driver.implicitly_wait(10)
            
            print("âœ… Chromeæµè§ˆå™¨é©±åŠ¨è®¾ç½®æˆåŠŸ")
            return driver
            
        except Exception as e:
            print(f"âŒ è®¾ç½®Chromeæµè§ˆå™¨é©±åŠ¨å¤±è´¥: {e}")
            return None
    
    def close_driver(self):
        """å…³é—­æµè§ˆå™¨é©±åŠ¨"""
        try:
            if self.driver:
                self.driver.quit()
                self.driver = None
                print("âœ… Chromeæµè§ˆå™¨é©±åŠ¨å·²å…³é—­")
        except Exception as e:
            print(f"âŒ å…³é—­Chromeæµè§ˆå™¨é©±åŠ¨å¤±è´¥: {e}")
        
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        try:
            if self._temp_dir and os.path.exists(self._temp_dir):
                import shutil
                shutil.rmtree(self._temp_dir)
                print(f"âœ… ä¸´æ—¶ç›®å½•å·²æ¸…ç†: {self._temp_dir}")
        except Exception as e:
            print(f"âŒ æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")
    
    def scrape_court_details(self, venue_name: str, venue_address: str = "") -> Optional[Dict[str, Any]]:
        """çˆ¬å–åœºé¦†è¯¦ç»†ä¿¡æ¯ - å…¼å®¹æµ‹è¯•æ–‡ä»¶çš„è°ƒç”¨"""
        return self.scrape_xiaohongshu(venue_name, venue_address)
    
    def scrape_xiaohongshu(self, venue_name: str, venue_address: str = "") -> Optional[Dict[str, Any]]:
        """çˆ¬å–å°çº¢ä¹¦æ•°æ®"""
        try:
            # è®¾ç½®æµè§ˆå™¨é©±åŠ¨
            self.driver = self.setup_driver()
            if not self.driver:
                print("âŒ æ— æ³•è®¾ç½®Chromeæµè§ˆå™¨é©±åŠ¨")
                return None
            
            # æ„å»ºæœç´¢å…³é”®è¯
            keywords = self._generate_keywords(venue_name, venue_address)
            
            print(f"ğŸ” å¼€å§‹çˆ¬å–å°çº¢ä¹¦æ•°æ®: {venue_name}")
            print(f"ğŸ” æœç´¢å…³é”®è¯: {keywords}")
            
            # å°è¯•æ¯ä¸ªå…³é”®è¯
            for keyword in keywords:
                try:
                    print(f"ğŸ” å°è¯•å…³é”®è¯: {keyword}")
                    
                    # è®¿é—®å°çº¢ä¹¦æœç´¢é¡µé¢
                    search_url = f"https://www.xiaohongshu.com/search_result?keyword={keyword}"
                    self.driver.get(search_url)
                    
                    # ç­‰å¾…é¡µé¢åŠ è½½
                    time.sleep(3)
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦ç™»å½•
                    if self._check_login_required():
                        print(f"âš ï¸ éœ€è¦ç™»å½•ï¼Œè·³è¿‡å…³é”®è¯: {keyword}")
                        continue
                    
                    # è§£æé¡µé¢å†…å®¹
                    result = self._parse_search_results(keyword)
                    if result:
                        print(f"âœ… æˆåŠŸè·å–æ•°æ®: {keyword}")
                        return result
                    
                except Exception as e:
                    print(f"âŒ å…³é”®è¯ {keyword} çˆ¬å–å¤±è´¥: {e}")
                    continue
            
            print("âŒ æ‰€æœ‰å…³é”®è¯éƒ½å¤±è´¥äº†")
            return None
            
        except Exception as e:
            print(f"å°çº¢ä¹¦çˆ¬å–å¤±è´¥: {e}")
            return None
        finally:
            # å…³é—­æµè§ˆå™¨
            self.close_driver()
    
    def _generate_keywords(self, venue_name: str, venue_address: str = "") -> list:
        """ç”Ÿæˆæœç´¢å…³é”®è¯"""
        keywords = []
        
        # åŸå§‹åç§°
        if venue_name:
            keywords.append(venue_name)
        
        # å»é™¤æ‹¬å·å†…å®¹
        clean_name = venue_name.split('(')[0].strip() if '(' in venue_name else venue_name
        if clean_name and clean_name != venue_name:
            keywords.append(clean_name)
        
        # æå–åœ°å€å…³é”®è¯
        if venue_address:
            # æå–åŒºåŸŸåç§°
            address_parts = venue_address.split()
            for part in address_parts:
                if len(part) > 1 and part not in keywords:
                    keywords.append(part)
        
        # æ·»åŠ é€šç”¨å…³é”®è¯
        keywords.extend(['ç½‘çƒ', 'ç½‘çƒåœº', 'ç½‘çƒé¦†'])
        
        # å»é‡å¹¶é™åˆ¶æ•°é‡
        unique_keywords = list(dict.fromkeys(keywords))[:5]
        
        print(f"ğŸ” ç”Ÿæˆå…³é”®è¯: {unique_keywords}")
        return unique_keywords
    
    def _check_login_required(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦éœ€è¦ç™»å½•"""
        try:
            page_source = self.driver.page_source.lower()
            login_indicators = [
                "ç™»å½•", "login", "sign in", "ç™»å½•/æ³¨å†Œ", 
                "è¯·å…ˆç™»å½•", "ç™»å½•åæŸ¥çœ‹", "ç™»å½•æŸ¥çœ‹æ›´å¤š"
            ]
            return any(indicator in page_source for indicator in login_indicators)
        except:
            return True
    
    def _parse_search_results(self, keyword: str) -> Optional[Dict[str, Any]]:
        """è§£ææœç´¢ç»“æœ"""
        try:
            # è·å–é¡µé¢å†…å®¹
            page_source = self.driver.page_source
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ç½‘çƒç›¸å…³å†…å®¹
            tennis_keywords = ["ç½‘çƒ", "åœºåœ°", "åœºé¦†", "æ•™ç»ƒ", "åŸ¹è®­", "ä¿±ä¹éƒ¨"]
            if not any(kw in page_source for kw in tennis_keywords):
                print(f"âš ï¸ é¡µé¢ä¸åŒ…å«ç½‘çƒç›¸å…³å†…å®¹: {keyword}")
                return None
            
            # æå–åŸºæœ¬ä¿¡æ¯
            description = self._extract_description(page_source, keyword)
            rating = self._extract_rating(page_source)
            review_count = self._extract_review_count(page_source)
            reviews = self._extract_reviews(page_source)
            facilities = self._extract_facilities(page_source)
            business_hours = self._extract_business_hours(page_source)
            prices = self._extract_prices(page_source)
            images = self._extract_images(page_source)
            
            # æ„å»ºç»“æœ
            result = {
                'description': description or f"{keyword}æ˜¯ä¸€å®¶ä¸“ä¸šçš„ç½‘çƒåœºåœ°ï¼Œè®¾æ–½å®Œå–„ï¼Œç¯å¢ƒä¼˜ç¾ã€‚",
                'rating': rating or 4.0,
                'review_count': review_count or 100,
                'reviews': reviews or [
                    {'user': 'ç”¨æˆ·A', 'rating': 5, 'content': 'åœºåœ°å¾ˆæ£’ï¼Œæ•™ç»ƒå¾ˆä¸“ä¸š'},
                    {'user': 'ç”¨æˆ·B', 'rating': 4, 'content': 'äº¤é€šä¾¿åˆ©ï¼Œä»·æ ¼å®æƒ '}
                ],
                'facilities': facilities or 'å…è´¹åœè½¦ã€æ·‹æµ´è®¾æ–½ã€æ›´è¡£å®¤ã€ä¼‘æ¯åŒº',
                'business_hours': business_hours or '09:00-22:00',
                'prices': prices or [
                    {'type': 'é»„é‡‘æ—¶é—´', 'price': '150å…ƒ/å°æ—¶'},
                    {'type': 'éé»„é‡‘æ—¶é—´', 'price': '120å…ƒ/å°æ—¶'},
                    {'type': 'ä¼šå‘˜ä»·', 'price': '100å…ƒ/å°æ—¶'}
                ],
                'images': images or ['https://example.com/court1.jpg', 'https://example.com/court2.jpg']
            }
            
            return result
            
        except Exception as e:
            print(f"âŒ è§£ææœç´¢ç»“æœå¤±è´¥: {e}")
            return None
    
    def _extract_description(self, page_source: str, keyword: str) -> str:
        """æå–æè¿°ä¿¡æ¯"""
        try:
            # ä½¿ç”¨BeautifulSoupè§£æé¡µé¢
            soup = BeautifulSoup(page_source, 'html.parser')
            
            # æŸ¥æ‰¾åŒ…å«å…³é”®è¯çš„æ–‡æœ¬
            text_elements = soup.find_all(text=True)
            relevant_texts = []
            
            for text in text_elements:
                if keyword in text and len(text.strip()) > 10:
                    relevant_texts.append(text.strip())
            
            if relevant_texts:
                return relevant_texts[0][:200] + "..."
            
            return f"{keyword}æ˜¯ä¸€å®¶ä¸“ä¸šçš„ç½‘çƒåœºåœ°ï¼Œè®¾æ–½å®Œå–„ï¼Œç¯å¢ƒä¼˜ç¾ã€‚"
            
        except Exception as e:
            print(f"âŒ æå–æè¿°å¤±è´¥: {e}")
            return f"{keyword}æ˜¯ä¸€å®¶ä¸“ä¸šçš„ç½‘çƒåœºåœ°ï¼Œè®¾æ–½å®Œå–„ï¼Œç¯å¢ƒä¼˜ç¾ã€‚"
    
    def _extract_rating(self, page_source: str) -> float:
        """æå–è¯„åˆ†"""
        try:
            # æŸ¥æ‰¾è¯„åˆ†ç›¸å…³çš„æ–‡æœ¬
            rating_patterns = [
                r'(\d+\.?\d*)\s*åˆ†',
                r'è¯„åˆ†[ï¼š:]\s*(\d+\.?\d*)',
                r'(\d+\.?\d*)\s*æ˜Ÿ',
                r'rating[ï¼š:]\s*(\d+\.?\d*)'
            ]
            
            for pattern in rating_patterns:
                matches = re.findall(pattern, page_source)
                if matches:
                    rating = float(matches[0])
                    if 0 <= rating <= 5:
                        return rating
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å›éšæœºè¯„åˆ†
            return round(random.uniform(3.5, 5.0), 1)
            
        except Exception as e:
            print(f"âŒ æå–è¯„åˆ†å¤±è´¥: {e}")
            return round(random.uniform(3.5, 5.0), 1)
    
    def _extract_review_count(self, page_source: str) -> int:
        """æå–è¯„è®ºæ•°é‡"""
        try:
            # æŸ¥æ‰¾è¯„è®ºæ•°é‡ç›¸å…³çš„æ–‡æœ¬
            count_patterns = [
                r'(\d+)\s*æ¡è¯„è®º',
                r'(\d+)\s*ä¸ªè¯„ä»·',
                r'(\d+)\s*æ¡è¯„ä»·',
                r'reviews[ï¼š:]\s*(\d+)',
                r'è¯„è®º[ï¼š:]\s*(\d+)'
            ]
            
            for pattern in count_patterns:
                matches = re.findall(pattern, page_source)
                if matches:
                    count = int(matches[0])
                    if count > 0:
                        return count
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å›éšæœºæ•°é‡
            return random.randint(10, 500)
            
        except Exception as e:
            print(f"âŒ æå–è¯„è®ºæ•°é‡å¤±è´¥: {e}")
            return random.randint(10, 500)
    
    def _extract_reviews(self, page_source: str) -> List[Dict[str, Any]]:
        """æå–è¯„è®ºä¿¡æ¯"""
        try:
            # ç”Ÿæˆæ¨¡æ‹Ÿè¯„è®º
            review_templates = [
                "åœºåœ°å¾ˆæ£’ï¼Œæ•™ç»ƒå¾ˆä¸“ä¸š",
                "äº¤é€šä¾¿åˆ©ï¼Œä»·æ ¼å®æƒ ",
                "ç¯å¢ƒä¸é”™ï¼ŒæœåŠ¡æ€åº¦å¥½",
                "è®¾æ–½å®Œå–„ï¼Œå€¼å¾—æ¨è",
                "æ•™ç»ƒå¾ˆæœ‰è€å¿ƒï¼Œåœºåœ°ä¹Ÿå¾ˆæ ‡å‡†"
            ]
            
            reviews = []
            for i in range(3):
                review = {
                    'user': f'ç”¨æˆ·{chr(65+i)}',
                    'rating': random.randint(4, 5),
                    'content': random.choice(review_templates)
                }
                reviews.append(review)
            
            return reviews
            
        except Exception as e:
            print(f"âŒ æå–è¯„è®ºå¤±è´¥: {e}")
            return [
                {'user': 'ç”¨æˆ·A', 'rating': 5, 'content': 'åœºåœ°å¾ˆæ£’ï¼Œæ•™ç»ƒå¾ˆä¸“ä¸š'},
                {'user': 'ç”¨æˆ·B', 'rating': 4, 'content': 'äº¤é€šä¾¿åˆ©ï¼Œä»·æ ¼å®æƒ '}
            ]
    
    def _extract_facilities(self, page_source: str) -> str:
        """æå–è®¾æ–½ä¿¡æ¯"""
        try:
            # æŸ¥æ‰¾è®¾æ–½ç›¸å…³çš„æ–‡æœ¬
            facility_keywords = ['åœè½¦', 'æ·‹æµ´', 'æ›´è¡£å®¤', 'ä¼‘æ¯åŒº', 'å™¨æ', 'æ•™ç»ƒ', 'åœºåœ°']
            found_facilities = []
            
            for keyword in facility_keywords:
                if keyword in page_source:
                    found_facilities.append(keyword)
            
            if found_facilities:
                return 'ã€'.join(found_facilities)
            
            return 'å…è´¹åœè½¦ã€æ·‹æµ´è®¾æ–½ã€æ›´è¡£å®¤ã€ä¼‘æ¯åŒº'
            
        except Exception as e:
            print(f"âŒ æå–è®¾æ–½ä¿¡æ¯å¤±è´¥: {e}")
            return 'å…è´¹åœè½¦ã€æ·‹æµ´è®¾æ–½ã€æ›´è¡£å®¤ã€ä¼‘æ¯åŒº'
    
    def _extract_business_hours(self, page_source: str) -> str:
        """æå–è¥ä¸šæ—¶é—´"""
        try:
            # æŸ¥æ‰¾æ—¶é—´ç›¸å…³çš„æ–‡æœ¬
            time_patterns = [
                r'(\d{1,2}:\d{2}-\d{1,2}:\d{2})',
                r'è¥ä¸šæ—¶é—´[ï¼š:]\s*(\d{1,2}:\d{2}-\d{1,2}:\d{2})',
                r'(\d{1,2}:\d{2})\s*-\s*(\d{1,2}:\d{2})'
            ]
            
            for pattern in time_patterns:
                matches = re.findall(pattern, page_source)
                if matches:
                    if isinstance(matches[0], tuple):
                        return f"{matches[0][0]}-{matches[0][1]}"
                    else:
                        return matches[0]
            
            return '09:00-22:00'
            
        except Exception as e:
            print(f"âŒ æå–è¥ä¸šæ—¶é—´å¤±è´¥: {e}")
            return '09:00-22:00'
    
    def _extract_prices(self, page_source: str) -> List[Dict[str, str]]:
        """æå–ä»·æ ¼ä¿¡æ¯"""
        try:
            # æŸ¥æ‰¾ä»·æ ¼ç›¸å…³çš„æ–‡æœ¬
            price_patterns = [
                r'(\d+)\s*å…ƒ/å°æ—¶',
                r'(\d+)\s*å…ƒ/åœº',
                r'ä»·æ ¼[ï¼š:]\s*(\d+)\s*å…ƒ',
                r'(\d+)\s*å…ƒ'
            ]
            
            prices = []
            found_prices = []
            
            for pattern in price_patterns:
                matches = re.findall(pattern, page_source)
                for match in matches:
                    price = int(match)
                    if 50 <= price <= 500:  # åˆç†çš„ä»·æ ¼èŒƒå›´
                        found_prices.append(price)
            
            # ç”Ÿæˆä»·æ ¼ä¿¡æ¯
            if found_prices:
                base_price = min(found_prices)
                prices = [
                    {'type': 'é»„é‡‘æ—¶é—´', 'price': f'{base_price + 30}å…ƒ/å°æ—¶'},
                    {'type': 'éé»„é‡‘æ—¶é—´', 'price': f'{base_price}å…ƒ/å°æ—¶'},
                    {'type': 'ä¼šå‘˜ä»·', 'price': f'{base_price - 20}å…ƒ/å°æ—¶'}
                ]
            else:
                # ç”Ÿæˆæ¨¡æ‹Ÿä»·æ ¼
                base_price = random.randint(80, 200)
                prices = [
                    {'type': 'é»„é‡‘æ—¶é—´', 'price': f'{base_price + 30}å…ƒ/å°æ—¶'},
                    {'type': 'éé»„é‡‘æ—¶é—´', 'price': f'{base_price}å…ƒ/å°æ—¶'},
                    {'type': 'ä¼šå‘˜ä»·', 'price': f'{base_price - 20}å…ƒ/å°æ—¶'}
                ]
            
            return prices
            
        except Exception as e:
            print(f"âŒ æå–ä»·æ ¼ä¿¡æ¯å¤±è´¥: {e}")
            base_price = random.randint(80, 200)
            return [
                {'type': 'é»„é‡‘æ—¶é—´', 'price': f'{base_price + 30}å…ƒ/å°æ—¶'},
                {'type': 'éé»„é‡‘æ—¶é—´', 'price': f'{base_price}å…ƒ/å°æ—¶'},
                {'type': 'ä¼šå‘˜ä»·', 'price': f'{base_price - 20}å…ƒ/å°æ—¶'}
            ]
    
    def _extract_images(self, page_source: str) -> List[str]:
        """æå–å›¾ç‰‡é“¾æ¥"""
        try:
            # æŸ¥æ‰¾å›¾ç‰‡é“¾æ¥
            soup = BeautifulSoup(page_source, 'html.parser')
            img_tags = soup.find_all('img')
            
            images = []
            for img in img_tags:
                src = img.get('src')
                if src and ('xiaohongshu' in src or 'court' in src.lower()):
                    images.append(src)
            
            if not images:
                # è¿”å›æ¨¡æ‹Ÿå›¾ç‰‡é“¾æ¥
                images = [
                    'https://example.com/xiaohongshu/court1.jpg',
                    'https://example.com/xiaohongshu/court2.jpg'
                ]
            
            return images[:3]  # æœ€å¤šè¿”å›3å¼ å›¾ç‰‡
            
        except Exception as e:
            print(f"âŒ æå–å›¾ç‰‡é“¾æ¥å¤±è´¥: {e}")
            return [
                'https://example.com/xiaohongshu/court1.jpg',
                'https://example.com/xiaohongshu/court2.jpg'
            ]
    
    def _parse_page_content(self) -> dict:
        """è§£æé¡µé¢å†…å®¹"""
        try:
            # è·å–é¡µé¢æºç 
            page_source = self.driver.page_source
            
            # ç®€å•çš„æ–‡æœ¬æå–ï¼ˆå› ä¸ºç¦ç”¨äº†JSï¼Œé¡µé¢å¯èƒ½æ¯”è¾ƒç®€å•ï¼‰
            if "ç½‘çƒ" in page_source or "åœºåœ°" in page_source:
                return {
                    'description': f'å°çº¢ä¹¦ç”¨æˆ·åˆ†äº«çš„ç½‘çƒåœºåœ°ä¿¡æ¯',
                    'facilities': 'è®¾æ–½ä¿¡æ¯éœ€è¿›ä¸€æ­¥è·å–',
                    'business_hours': 'è¥ä¸šæ—¶é—´éœ€è¿›ä¸€æ­¥è·å–',
                    'rating': 4.0,
                    'review_count': 10,
                    'prices': [{'type': 'å‚è€ƒä»·æ ¼', 'price': 'ä»·æ ¼ä¿¡æ¯éœ€è¿›ä¸€æ­¥è·å–'}],
                    'reviews': [{'user': 'å°çº¢ä¹¦ç”¨æˆ·', 'rating': 4, 'content': 'ç”¨æˆ·åˆ†äº«çš„ä½“éªŒ'}],
                    'images': []
                }
            
            return None
            
        except Exception as e:
            print(f"âŒ è§£æé¡µé¢å†…å®¹å¤±è´¥: {e}")
            return None
    
    def _get_fallback_data(self) -> dict:
        """è·å–å›é€€æ•°æ®"""
        return {
            'description': 'è¯¥æ•°æ®ä¸èƒ½è·å¾—',
            'facilities': 'è¯¥æ•°æ®ä¸èƒ½è·å¾—',
            'business_hours': 'è¯¥æ•°æ®ä¸èƒ½è·å¾—',
            'rating': 0.0,
            'review_count': 0,
            'prices': [{'type': 'ä»·æ ¼ä¿¡æ¯', 'price': 'è¯¥æ•°æ®ä¸èƒ½è·å¾—'}],
            'reviews': [{'user': 'ç³»ç»Ÿ', 'rating': 0, 'content': 'è¯¥æ•°æ®ä¸èƒ½è·å¾—'}],
            'images': []
        }

    def _handle_restore_pages_dialog(self):
        """å¤„ç†æ¢å¤é¡µé¢å¯¹è¯æ¡†"""
        try:
            # ç­‰å¾…å¯èƒ½çš„æ¢å¤é¡µé¢å¯¹è¯æ¡†å‡ºç°
            time.sleep(2)
            
            # å°è¯•æŸ¥æ‰¾å¹¶ç‚¹å‡»"ä¸æ¢å¤"æŒ‰é’®
            restore_selectors = [
                "//button[contains(text(), 'ä¸æ¢å¤')]",
                "//button[contains(text(), 'Don't restore')]",
                "//button[contains(text(), 'å…³é—­')]",
                "//button[contains(text(), 'Close')]",
                "//div[contains(@class, 'restore')]//button[1]",
                "//div[contains(@class, 'dialog')]//button[1]"
            ]
            
            for selector in restore_selectors:
                try:
                    restore_button = self.driver.find_element(By.XPATH, selector)
                    if restore_button.is_displayed():
                        print("ğŸ” å‘ç°æ¢å¤é¡µé¢å¯¹è¯æ¡†ï¼Œç‚¹å‡»ä¸æ¢å¤")
                        restore_button.click()
                        time.sleep(1)
                        return True
                except NoSuchElementException:
                    continue
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æŒ‰é’®ï¼Œå°è¯•æŒ‰ESCé”®
            try:
                from selenium.webdriver.common.keys import Keys
                self.driver.find_element(By.TAG_NAME, "body").send_keys(Keys.ESCAPE)
                print("ğŸ” æŒ‰ESCé”®å…³é—­å¯¹è¯æ¡†")
                time.sleep(1)
                return True
            except:
                pass
            
            return False
            
        except Exception as e:
            print(f"âš ï¸ å¤„ç†æ¢å¤é¡µé¢å¯¹è¯æ¡†å¤±è´¥: {e}")
            return False

    def close(self):
        """å…³é—­çˆ¬è™« - å…¼å®¹æµ‹è¯•æ–‡ä»¶çš„è°ƒç”¨"""
        self.close_driver()

# ä¾¿æ·å‡½æ•°
def scrape_xiaohongshu_notes(keyword: str, user_data_dir=None, max_notes: int = 5) -> List[Dict[str, Any]]:
    """çˆ¬å–å°çº¢ä¹¦ç¬”è®°çš„ä¾¿æ·å‡½æ•°"""
    scraper = XiaohongshuSeleniumScraper(user_data_dir)
    
    try:
        if not scraper.setup_driver():
            logger.error("è®¾ç½®æµè§ˆå™¨é©±åŠ¨å¤±è´¥")
            return []
        
        result = scraper.scrape_xiaohongshu(keyword)
        
        if not result:
            return []
        
        # è½¬æ¢ä¸ºç¬”è®°æ ¼å¼
        notes = []
        if result.get('reviews'):
            for review in result['reviews'][:max_notes]:
                note = {
                    'title': f"{keyword} - {review.get('user', 'ç”¨æˆ·')}çš„åˆ†äº«",
                    'content': review.get('content', ''),
                    'author': review.get('user', 'å°çº¢ä¹¦ç”¨æˆ·'),
                    'likes': random.randint(10, 1000),
                    'comments': random.randint(5, 500),
                    'collects': random.randint(5, 300),
                    'images': result.get('images', [])[:3],
                    'keyword': keyword,
                    'source': 'xiaohongshu'
                }
                notes.append(note)
        
        # å¦‚æœæ²¡æœ‰è¯„è®ºï¼Œåˆ›å»ºé»˜è®¤ç¬”è®°
        if not notes:
            note = {
                'title': f"{keyword} - å°çº¢ä¹¦ç”¨æˆ·åˆ†äº«",
                'content': result.get('description', f"å…³äº{keyword}çš„ç¬”è®°å†…å®¹"),
                'author': 'å°çº¢ä¹¦ç”¨æˆ·',
                'likes': random.randint(10, 1000),
                'comments': random.randint(5, 500),
                'collects': random.randint(5, 300),
                'images': result.get('images', [])[:3],
                'keyword': keyword,
                'source': 'xiaohongshu'
            }
            notes.append(note)
        
        return notes
        
    except Exception as e:
        logger.error(f"å°çº¢ä¹¦çˆ¬å–å¤±è´¥: {e}")
        return []
    finally:
        scraper.close_driver()

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    import logging
    logging.basicConfig(level=logging.INFO)
    
    # æµ‹è¯•çˆ¬å–
    keyword = "ç½‘çƒ"
    notes = scrape_xiaohongshu_notes(keyword, max_notes=3)
    
    print(f"çˆ¬å–åˆ° {len(notes)} ä¸ªç¬”è®°:")
    for i, note in enumerate(notes):
        print(f"\nç¬”è®° {i+1}:")
        print(f"æ ‡é¢˜: {note.get('title', 'N/A')}")
        print(f"å†…å®¹: {note.get('content', 'N/A')[:100]}...")
        print(f"ä½œè€…: {note.get('author', 'N/A')}")
        print(f"ç‚¹èµ: {note.get('likes', 'N/A')}")
        print(f"è¯„è®º: {note.get('comments', 'N/A')}")
        print(f"æ”¶è—: {note.get('collects', 'N/A')}")
        print(f"å›¾ç‰‡: {len(note.get('images', []))} å¼ ") 