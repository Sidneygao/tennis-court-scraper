#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡é‡æ–°è®¡ç®—æ‰€æœ‰åœºé¦†é¢„æµ‹
ä½¿ç”¨ä¿®å¤åçš„6KMæ­¥è¿›æ³•ç®—æ³•ï¼ˆå®¤å¤–6KMï¼Œå®¤å†…3-4KMï¼‰
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.database import get_db
from app.models import TennisCourt, CourtDetail
from app.scrapers.price_predictor import PricePredictor
import json
from datetime import datetime

def batch_recalculate_all_predictions():
    print("ğŸ”„ æ‰¹é‡é‡æ–°è®¡ç®—æ‰€æœ‰åœºé¦†é¢„æµ‹...")
    print("ğŸ“‹ ä½¿ç”¨ä¿®å¤åçš„6KMæ­¥è¿›æ³•ç®—æ³•")
    print("   - å®¤å¤–åœºé¦†ï¼šæœ€å¤§åŠå¾„6KMï¼Œæ­¥è¿›[1,2,3,4,5,6]")
    print("   - å®¤å†…åœºé¦†ï¼šæ ¸å¿ƒåŒº3KMï¼Œéæ ¸å¿ƒåŒº4KM")
    print("   - ä¸¥æ ¼åŒç±»å‹è¿‡æ»¤")
    print("   - æ”¯æŒç»¼åˆæŠ¥ä»·ç±»å‹")
    print("=" * 80)
    
    # åˆå§‹åŒ–é¢„æµ‹å™¨
    predictor = PricePredictor()
    
    # è·å–æ‰€æœ‰åœºé¦†
    all_courts = predictor.db.query(TennisCourt).all()
    print(f"ğŸ“Š æ€»åœºé¦†æ•°é‡: {len(all_courts)}")
    
    # ç»Ÿè®¡å˜é‡
    total_count = 0
    success_count = 0
    failed_count = 0
    no_data_count = 0
    
    # æŒ‰åŒºåŸŸåˆ†ç»„å¤„ç†
    areas = {}
    for court in all_courts:
        area = getattr(court, 'area', 'unknown')
        if area not in areas:
            areas[area] = []
        areas[area].append(court)
    
    print(f"ğŸ“‹ æŒ‰åŒºåŸŸåˆ†ç»„: {list(areas.keys())}")
    print("=" * 80)
    
    for area_name, courts in areas.items():
        print(f"\nğŸ˜ï¸ å¤„ç†åŒºåŸŸ: {area_name} ({len(courts)}ä¸ªåœºé¦†)")
        
        for i, court in enumerate(courts, 1):
            total_count += 1
            
            print(f"\n  [{i}/{len(courts)}] {court.name}")
            
            # åˆ¤æ–­åœºé¦†ç±»å‹
            court_type = predictor.determine_court_type(court.name)
            print(f"    ç±»å‹: {court_type}")
            
            # é¢„æµ‹ä»·æ ¼
            try:
                prediction = predictor.predict_price_for_court(court)
                
                if prediction and not prediction.get('predict_failed'):
                    # é¢„æµ‹æˆåŠŸ
                    success_count += 1
                    peak_price = prediction.get('peak_price')
                    off_peak_price = prediction.get('off_peak_price')
                    search_radius = prediction.get('search_radius')
                    data_count = prediction.get('data_count')
                    
                    print(f"    âœ… é¢„æµ‹æˆåŠŸ: é»„é‡‘{peak_price}å…ƒ, éé»„é‡‘{off_peak_price}å…ƒ")
                    print(f"       æœç´¢åŠå¾„: {search_radius}KM, æ ·æœ¬æ•°: {data_count}ä¸ª")
                    
                    # ä¿å­˜é¢„æµ‹ç»“æœ
                    detail = predictor.db.query(CourtDetail).filter(CourtDetail.court_id == court.id).first()
                    if not detail:
                        detail = CourtDetail(court_id=court.id)
                        predictor.db.add(detail)
                        predictor.db.commit()
                        predictor.db.refresh(detail)
                    
                    detail.predict_prices = json.dumps(prediction, ensure_ascii=False)
                    predictor.db.commit()
                    
                elif prediction and prediction.get('predict_failed'):
                    # é¢„æµ‹å¤±è´¥ - æ•°æ®ä¸è¶³
                    failed_count += 1
                    reason = prediction.get('reason', 'æœªçŸ¥åŸå› ')
                    print(f"    âŒ é¢„æµ‹å¤±è´¥: {reason}")
                    
                else:
                    # å…¶ä»–åŸå› å¤±è´¥
                    failed_count += 1
                    print(f"    âŒ é¢„æµ‹å¤±è´¥: æœªçŸ¥åŸå› ")
                    
            except Exception as e:
                failed_count += 1
                print(f"    âŒ é¢„æµ‹å¼‚å¸¸: {e}")
                try:
                    predictor.db.rollback()
                except:
                    pass
    
    # ç»Ÿè®¡ç»“æœ
    print("\n" + "=" * 80)
    print("ğŸ“Š æ‰¹é‡é¢„æµ‹å®Œæˆç»Ÿè®¡:")
    print(f"   æ€»åœºé¦†æ•°: {total_count}")
    print(f"   é¢„æµ‹æˆåŠŸ: {success_count}")
    print(f"   é¢„æµ‹å¤±è´¥: {failed_count}")
    print(f"   æˆåŠŸç‡: {success_count/(total_count or 1)*100:.1f}%")
    
    # æŒ‰åŒºåŸŸç»Ÿè®¡
    print(f"\nğŸ“‹ æŒ‰åŒºåŸŸç»Ÿè®¡:")
    for area_name, courts in areas.items():
        area_success = 0
        area_failed = 0
        for court in courts:
            detail = predictor.db.query(CourtDetail).filter(CourtDetail.court_id == court.id).first()
            if detail and detail.predict_prices:
                try:
                    predict_data = json.loads(detail.predict_prices)
                    if predict_data and not predict_data.get('predict_failed'):
                        area_success += 1
                    else:
                        area_failed += 1
                except:
                    area_failed += 1
            else:
                area_failed += 1
        
        area_total = len(courts)
        area_rate = area_success/(area_total or 1)*100
        print(f"   {area_name}: {area_success}/{area_total} ({area_rate:.1f}%)")
    
    predictor.db.close()
    print(f"\nâœ… æ‰¹é‡é‡æ–°è®¡ç®—å®Œæˆ!")

if __name__ == "__main__":
    batch_recalculate_all_predictions() 