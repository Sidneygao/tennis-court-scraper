#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ”¹è¿›çš„å°çº¢ä¹¦çˆ¬è™«æµ‹è¯•è„šæœ¬
æµ‹è¯•çœŸå®çš„å°çº¢ä¹¦æ•°æ®çˆ¬å–åŠŸèƒ½
"""

import sys
import os
import time
import json
import logging
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.scrapers.xiaohongshu_selenium import XiaohongshuSeleniumScraper

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('xiaohongshu_test.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

def test_xiaohongshu_scraper():
    """æµ‹è¯•å°çº¢ä¹¦çˆ¬è™«"""
    print("ğŸ¾ æ”¹è¿›çš„å°çº¢ä¹¦çˆ¬è™«æµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•åœºé¦†åˆ—è¡¨
    test_courts = [
        "ä¹¾å¤ä½“è‚²ç½‘çƒå­¦ç»ƒé¦†(æœ›äº¬SOHOT1å•†åœºåº—)",
        "SOLOTennisç½‘çƒä¿±ä¹éƒ¨",
        "åŠ¨ä¹‹å…‰Â·å¤§æœ›è·¯ç½‘çƒé¦†",
        "çƒæ˜Ÿç½‘çƒæ±‡(åˆç”Ÿæ±‡çƒæ˜Ÿè¿åŠ¨ä¸­å¿ƒåº—)",
        "èŒ‚åUHNå›½é™…æ‘-ç½‘çƒåœº"
    ]
    
    results = {}
    
    for i, court_name in enumerate(test_courts, 1):
        print(f"\nğŸ“‹ æµ‹è¯• {i}/{len(test_courts)}: {court_name}")
        print("-" * 40)
        
        scraper = None
        try:
            # ä¸ºæ¯ä¸ªæµ‹è¯•åˆ›å»ºæ–°çš„çˆ¬è™«å®ä¾‹
            scraper = XiaohongshuSeleniumScraper()
            
            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = time.time()
            
            # æ‰§è¡Œçˆ¬å–
            data = scraper.scrape_court_details(court_name)
            
            # è®°å½•ç»“æŸæ—¶é—´
            end_time = time.time()
            duration = end_time - start_time
            
            if data:
                # ä¿å­˜ç»“æœ
                results[court_name] = {
                    "success": True,
                    "duration": round(duration, 2),
                    "data": data,
                    "timestamp": datetime.now().isoformat()
                }
                
                # æ‰“å°ç»“æœæ‘˜è¦
                print(f"âœ… çˆ¬å–æˆåŠŸ (è€—æ—¶: {duration:.2f}ç§’)")
                print(f"   è¯„åˆ†: {data.get('rating', 'N/A')}")
                print(f"   è¯„è®ºæ•°: {data.get('review_count', 'N/A')}")
                print(f"   ä»·æ ¼æ•°é‡: {len(data.get('prices', []))}")
                print(f"   è¯„è®ºæ•°é‡: {len(data.get('reviews', []))}")
                print(f"   æè¿°: {data.get('description', 'N/A')[:50]}...")
                
                # æ‰“å°ä»·æ ¼ä¿¡æ¯
                if data.get('prices'):
                    print("   ä»·æ ¼ä¿¡æ¯:")
                    for price in data['prices']:
                        print(f"     {price.get('type', 'N/A')}: {price.get('price', 'N/A')}")
                
            else:
                print(f"âŒ çˆ¬å–å¤±è´¥: æœªè·å–åˆ°æ•°æ®")
                results[court_name] = {
                    "success": False,
                    "error": "æœªè·å–åˆ°æ•°æ®",
                    "timestamp": datetime.now().isoformat()
                }
                
        except Exception as e:
            print(f"âŒ çˆ¬å–å¤±è´¥: {e}")
            results[court_name] = {
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
        
        finally:
            # ç¡®ä¿å…³é—­æµè§ˆå™¨
            if scraper:
                try:
                    scraper.close()
                    print("ğŸ”’ æµè§ˆå™¨å·²å…³é—­")
                except:
                    pass
        
        # æ·»åŠ å»¶è¿Ÿé¿å…è¿‡äºé¢‘ç¹
        if i < len(test_courts):
            print("â³ ç­‰å¾…10ç§’...")
            time.sleep(10)
    
    # ä¿å­˜æµ‹è¯•ç»“æœ
    result_file = f'xiaohongshu_improved_test_results_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    # ç»Ÿè®¡ç»“æœ
    success_count = sum(1 for r in results.values() if r.get('success', False))
    total_count = len(results)
    
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœç»Ÿè®¡")
    print("=" * 50)
    print(f"æ€»æµ‹è¯•æ•°: {total_count}")
    print(f"æˆåŠŸæ•°: {success_count}")
    print(f"å¤±è´¥æ•°: {total_count - success_count}")
    print(f"æˆåŠŸç‡: {success_count/total_count*100:.1f}%")
    
    if success_count > 0:
        avg_duration = sum(r.get('duration', 0) for r in results.values() if r.get('success', False)) / success_count
        print(f"å¹³å‡è€—æ—¶: {avg_duration:.2f}ç§’")
    
    print(f"\nğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
    
    # æ‰“å°æˆåŠŸæ¡ˆä¾‹çš„è¯¦ç»†ä¿¡æ¯
    if success_count > 0:
        print(f"\nğŸ“‹ æˆåŠŸæ¡ˆä¾‹è¯¦æƒ…:")
        print("-" * 30)
        for court_name, result in results.items():
            if result.get('success'):
                data = result.get('data', {})
                print(f"\nğŸŸï¸ {court_name}:")
                print(f"   è¯„åˆ†: {data.get('rating', 'N/A')}")
                print(f"   è¯„è®ºæ•°: {data.get('review_count', 'N/A')}")
                print(f"   è¥ä¸šæ—¶é—´: {data.get('business_hours', 'N/A')}")
                print(f"   è®¾æ–½: {data.get('facilities', 'N/A')}")
                if data.get('prices'):
                    print("   ä»·æ ¼:")
                    for price in data['prices']:
                        print(f"     {price.get('type', 'N/A')}: {price.get('price', 'N/A')}")

def test_single_court():
    """æµ‹è¯•å•ä¸ªåœºé¦†"""
    print("ğŸ¾ å•ä¸ªåœºé¦†æµ‹è¯•")
    print("=" * 30)
    
    court_name = "ä¹¾å¤ä½“è‚²ç½‘çƒå­¦ç»ƒé¦†(æœ›äº¬SOHOT1å•†åœºåº—)"
    print(f"æµ‹è¯•åœºé¦†: {court_name}")
    
    scraper = None
    try:
        scraper = XiaohongshuSeleniumScraper()
        
        start_time = time.time()
        data = scraper.scrape_court_details(court_name)
        end_time = time.time()
        
        if data:
            print(f"âœ… çˆ¬å–æˆåŠŸ (è€—æ—¶: {end_time - start_time:.2f}ç§’)")
            print("\nğŸ“‹ è¯¦ç»†æ•°æ®:")
            print(json.dumps(data, ensure_ascii=False, indent=2))
        else:
            print("âŒ çˆ¬å–å¤±è´¥")
            
    except Exception as e:
        print(f"âŒ çˆ¬å–å¤±è´¥: {e}")
    finally:
        if scraper:
            scraper.close()

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='å°çº¢ä¹¦çˆ¬è™«æµ‹è¯•')
    parser.add_argument('--single', action='store_true', help='æµ‹è¯•å•ä¸ªåœºé¦†')
    parser.add_argument('--court', type=str, help='æŒ‡å®šåœºé¦†åç§°')
    
    args = parser.parse_args()
    
    if args.single:
        if args.court:
            # æµ‹è¯•æŒ‡å®šåœºé¦†
            court_name = args.court
            print(f"ğŸ¾ æµ‹è¯•æŒ‡å®šåœºé¦†: {court_name}")
            print("=" * 30)
            
            scraper = None
            try:
                scraper = XiaohongshuSeleniumScraper()
                
                start_time = time.time()
                data = scraper.scrape_court_details(court_name)
                end_time = time.time()
                
                if data:
                    print(f"âœ… çˆ¬å–æˆåŠŸ (è€—æ—¶: {end_time - start_time:.2f}ç§’)")
                    print("\nğŸ“‹ è¯¦ç»†æ•°æ®:")
                    print(json.dumps(data, ensure_ascii=False, indent=2))
                else:
                    print("âŒ çˆ¬å–å¤±è´¥")
                    
            except Exception as e:
                print(f"âŒ çˆ¬å–å¤±è´¥: {e}")
            finally:
                if scraper:
                    scraper.close()
        else:
            test_single_court()
    else:
        test_xiaohongshu_scraper() 