#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
BINGå¤šå…³é”®å­—ä»·æ ¼çˆ¬å–è„šæœ¬ - å¢å¼ºç‰ˆ
ä¼˜åŒ–ç­–ç•¥ä»¥è·å–æ›´å¤šæ•°æ®ï¼Œé›†æˆç½®ä¿¡åº¦æ¨¡å‹
"""

import os
import sys
import json
import time
import re
import logging
from datetime import datetime
from typing import List, Dict, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import quote_plus

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.dirname(__file__)))

from app.database import get_db
from app.models import TennisCourt, CourtDetail
from app.scrapers.price_confidence_model import confidence_model

# Seleniumç›¸å…³å¯¼å…¥
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class BingPriceSpiderEnhanced:
    """å¢å¼ºç‰ˆBINGä»·æ ¼çˆ¬è™«"""
    
    def __init__(self, headless: bool = True):
        self.headless = headless
        self.driver = None
        self.db = next(get_db())
        
        # åˆå§‹åŒ–ç½®ä¿¡åº¦æ¨¡å‹
        logger.info("ğŸ”„ åˆå§‹åŒ–ä»·æ ¼ç½®ä¿¡åº¦æ¨¡å‹...")
        confidence_model.build_normal_distribution_models()
        model_info = confidence_model.get_model_info()
        logger.info(f"âœ… ç½®ä¿¡åº¦æ¨¡å‹åˆå§‹åŒ–å®Œæˆ:")
        for model_name, model_data in model_info.items():
            if model_data:
                logger.info(f"  {model_name}: å‡å€¼={model_data['mean']:.1f}, æ ‡å‡†å·®={model_data['std']:.1f}, æ ·æœ¬æ•°={model_data['count']}")
    
    def setup_driver(self):
        """è®¾ç½®Chromeé©±åŠ¨"""
        chrome_options = Options()
        if self.headless:
            chrome_options.add_argument("--headless")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--window-size=1920,1080")
        chrome_options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")
        
        # æ·»åŠ æ›´å¤šåæ£€æµ‹å‚æ•°
        chrome_options.add_argument("--disable-blink-features=AutomationControlled")
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        
        self.driver = webdriver.Chrome(options=chrome_options)
        self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
    
    def close_driver(self):
        """å…³é—­é©±åŠ¨"""
        if self.driver:
            self.driver.quit()
    
    def get_courts_for_enhanced_crawl(self) -> list:
        """
        è·å–éœ€è¦å¢å¼ºçˆ¬å–çš„åœºé¦†ï¼š
        1. å®Œå…¨æ²¡æœ‰BINGä»·æ ¼æ•°æ®çš„åœºé¦†
        2. åªæœ‰é¢„æµ‹ä»·æ ¼ä½†æ— BINGä»·æ ¼çš„åœºé¦†
        """
        courts = self.db.query(TennisCourt).all()
        result = []
        
        for court in courts:
            # æ£€æŸ¥è¯¦æƒ…è¡¨
            detail = self.db.query(CourtDetail).filter(CourtDetail.court_id == court.id).first()
            if not detail:
                detail = CourtDetail(court_id=court.id)
                self.db.add(detail)
                self.db.commit()
                self.db.refresh(detail)
            
            # æ£€æŸ¥BINGä»·æ ¼æ•°æ®
            has_bing_prices = False
            bing_price_count = 0
            
            if detail and detail.bing_prices:
                try:
                    bing_data = json.loads(detail.bing_prices)
                    if isinstance(bing_data, list) and len(bing_data) > 0:
                        has_bing_prices = True
                        bing_price_count = len(bing_data)
                except:
                    pass
            
            # åªçˆ¬å–æ²¡æœ‰BINGä»·æ ¼æ•°æ®çš„åœºé¦†
            if not has_bing_prices:
                result.append({
                    'court_id': court.id,
                    'court_name': court.name,
                    'court_address': court.address,
                    'court_type': court.court_type or '',
                    'detail_id': detail.id if detail else None,
                    'price_status': {
                        'has_bing_prices': has_bing_prices,
                        'bing_price_count': bing_price_count
                    }
                })
        
        logger.info(f"æ‰¾åˆ° {len(result)} ä¸ªéœ€è¦å¢å¼ºçˆ¬å–çš„åœºé¦†ï¼ˆæ— BINGä»·æ ¼æ•°æ®ï¼‰")
        return result
    
    def generate_enhanced_keywords(self, court_name: str, court_address: str) -> List[str]:
        """ç”Ÿæˆå¢å¼ºç‰ˆæœç´¢å…³é”®è¯"""
        # æ¸…ç†åœºé¦†åç§°
        clean_name = re.sub(r'\([^)]*\)', '', court_name).strip()
        
        # æå–åœ°å€å…³é”®è¯
        address_keywords = []
        if court_address:
            # æå–åŒºåŸŸä¿¡æ¯
            area_patterns = [r'([^åŒº]+åŒº)', r'([^è·¯]+è·¯)', r'([^è¡—]+è¡—)']
            for pattern in area_patterns:
                matches = re.findall(pattern, court_address)
                address_keywords.extend(matches)
        
        # åŸºç¡€å…³é”®è¯
        base_keywords = [
            f"{clean_name} ç½‘çƒä»·æ ¼",
            f"{clean_name} ç½‘çƒé¢„è®¢",
            f"{clean_name} ç½‘çƒè´¹ç”¨",
            f"{clean_name} ç½‘çƒæ”¶è´¹",
            f"{clean_name} ä»·æ ¼",
            f"{clean_name} é¢„è®¢",
            f"{clean_name} æ”¶è´¹æ ‡å‡†",
            f"{clean_name} ä¼šå‘˜ä»·æ ¼",
            f"{clean_name} å­¦ç”Ÿä»·æ ¼"
        ]
        
        # åœ°å€ç›¸å…³å…³é”®è¯
        address_keywords = []
        if court_address:
            for area in address_keywords[:2]:  # æœ€å¤š2ä¸ªåœ°å€å…³é”®è¯
                address_keywords.extend([
                    f"{clean_name} {area} ç½‘çƒä»·æ ¼",
                    f"{area} {clean_name} ä»·æ ¼",
                    f"{clean_name} {area} é¢„è®¢"
                ])
        
        # ç»„åˆå…³é”®è¯
        all_keywords = base_keywords + address_keywords
        
        # å»é‡å¹¶é™åˆ¶æ•°é‡
        unique_keywords = list(dict.fromkeys(all_keywords))
        return unique_keywords[:8]  # æœ€å¤š8ä¸ªå…³é”®è¯
    
    def search_bing_enhanced(self, keyword: str) -> List[Dict]:
        """å¢å¼ºç‰ˆBINGæœç´¢"""
        try:
            search_url = f"https://www.bing.com/search?q={quote_plus(keyword)}&count=20"
            self.driver.get(search_url)
            
            # ç­‰å¾…é¡µé¢åŠ è½½
            time.sleep(2)
            
            # å°è¯•æ»šåŠ¨é¡µé¢è·å–æ›´å¤šç»“æœ
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(1)
            
            search_results = []
            
            # æŸ¥æ‰¾æ›´å¤šç±»å‹çš„ç»“æœ
            selectors = [
                "li.b_algo",  # æ™®é€šæœç´¢ç»“æœ
                ".b_attribution cite",  # æ–°é—»ç»“æœ
                ".b_caption p",  # æ‘˜è¦
                ".b_attribution"  # æ¥æºä¿¡æ¯
            ]
            
            for selector in selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for element in elements[:10]:  # æ¯ä¸ªç±»å‹æœ€å¤š10ä¸ª
                        try:
                            text = element.get_attribute("textContent").strip()
                            if text and len(text) > 10:
                                search_results.append({
                                    "title": keyword,
                                    "snippet": text,
                                    "link": "",
                                    "type": selector
                                })
                        except:
                            continue
                except:
                    continue
            
            return search_results[:15]  # æœ€å¤š15ä¸ªç»“æœ
            
        except Exception as e:
            logger.error(f"BINGæœç´¢å¤±è´¥: {e}")
            return []
    
    def extract_prices_enhanced(self, text: str, court_name: str = "", court_type: str = "") -> List[Dict]:
        """å¢å¼ºç‰ˆä»·æ ¼æå–ï¼Œé›†æˆç½®ä¿¡åº¦è®¡ç®—"""
        prices = []
        
        # æ‰©å±•ä»·æ ¼æ¨¡å¼
        price_patterns = [
            r'(\d+)[\s\-]*å…ƒ/å°æ—¶',
            r'(\d+)[\s\-]*å…ƒ/æ—¶',
            r'(\d+)[\s\-]*å…ƒ',
            r'Â¥(\d+)',
            r'ï¿¥(\d+)',
            r'(\d+)[\s\-]*å—/å°æ—¶',
            r'(\d+)[\s\-]*å—/æ—¶',
            r'(\d+)[\s\-]*å…ƒ/åœº',
            r'(\d+)[\s\-]*å…ƒ/æ¬¡',
            r'(\d+)[\s\-]*å…ƒ/äºº',
            r'(\d+)[\s\-]*å…ƒ/å¤©',
            r'(\d+)[\s\-]*å…ƒ/æœˆ',
            r'(\d+)[\s\-]*å…ƒ/å¹´',
            r'(\d+)[\s\-]*å…ƒ/ä¼šå‘˜',
            r'(\d+)[\s\-]*å…ƒ/å­¦ç”Ÿ'
        ]
        
        for pattern in price_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                try:
                    price_value = int(match)
                    # æ”¾å®½ä»·æ ¼èŒƒå›´
                    if 10 <= price_value <= 2000:
                        # æ ¹æ®æ¨¡å¼æ¨æ–­ä»·æ ¼ç±»å‹
                        price_type = "æ ‡å‡†ä»·æ ¼"
                        if "ä¼šå‘˜" in pattern:
                            price_type = "ä¼šå‘˜ä»·æ ¼"
                        elif "å­¦ç”Ÿ" in pattern:
                            price_type = "å­¦ç”Ÿä»·æ ¼"
                        elif "åœº" in pattern or "æ¬¡" in pattern:
                            price_type = "æŒ‰åœºæ¬¡ä»·æ ¼"
                        elif "å¤©" in pattern:
                            price_type = "æ—¥ç§Ÿä»·æ ¼"
                        elif "æœˆ" in pattern or "å¹´" in pattern:
                            price_type = "é•¿æœŸä»·æ ¼"
                        
                        # è®¡ç®—ç½®ä¿¡åº¦
                        confidence = confidence_model.calculate_confidence(
                            price_value, court_type, court_name, price_type
                        )
                        
                        prices.append({
                            "price": f"Â¥{price_value}/å°æ—¶",
                            "value": price_value,
                            "pattern": pattern,
                            "type": price_type,
                            "confidence": confidence
                        })
                except ValueError:
                    continue
        
        # å»é‡
        unique_prices = []
        seen_values = set()
        for price in prices:
            if price["value"] not in seen_values:
                unique_prices.append(price)
                seen_values.add(price["value"])
        
        return unique_prices
    
    def crawl_bing_prices_enhanced(self, court_data: Dict) -> Dict:
        """å¢å¼ºç‰ˆå•ä¸ªåœºé¦†ä»·æ ¼çˆ¬å–"""
        try:
            court_name = court_data['court_name']
            court_address = court_data['court_address']
            court_type = court_data.get('court_type', '')
            logger.info(f"å¼€å§‹å¢å¼ºçˆ¬å–åœºé¦†ä»·æ ¼: {court_name}")
            
            # ç”Ÿæˆå¢å¼ºå…³é”®è¯
            keywords = self.generate_enhanced_keywords(court_name, court_address)
            
            all_prices = []
            found_prices_count = 0
            
            print(f"\nğŸ¾ æ­£åœ¨çˆ¬å–: {court_name}")
            print(f"ğŸ“ åœ°å€: {court_address}")
            print(f"ğŸ” ä½¿ç”¨å…³é”®è¯: {len(keywords)} ä¸ª")
            
            for i, keyword in enumerate(keywords, 1):
                print(f"\n  [{i}/{len(keywords)}] æœç´¢: {keyword}")
                
                # æœç´¢BING
                search_results = self.search_bing_enhanced(keyword)
                print(f"     ğŸ“„ æ‰¾åˆ° {len(search_results)} ä¸ªæœç´¢ç»“æœ")
                
                # æå–ä»·æ ¼
                keyword_prices = []
                for result in search_results:
                    snippet_prices = self.extract_prices_enhanced(
                        result["snippet"], court_name, court_type
                    )
                    
                    for price in snippet_prices:
                        price_info = {
                            "type": price.get("type", "æ ‡å‡†ä»·æ ¼"),
                            "price": price["price"],
                            "source": "BING",
                            "keyword": keyword,
                            "confidence": price.get("confidence", 0.8),
                            "title": result["title"],
                            "link": result.get("link", ""),
                            "extracted_from": result.get("type", "snippet")
                        }
                        all_prices.append(price_info)
                        keyword_prices.append(price_info)
                
                # åŠ¨æ€æ˜¾ç¤ºå½“å‰å…³é”®è¯æ‰¾åˆ°çš„ä»·æ ¼
                if keyword_prices:
                    print(f"     ğŸ’° æå–åˆ° {len(keyword_prices)} ä¸ªä»·æ ¼:")
                    for price in keyword_prices:
                        confidence_str = f"{price['confidence']:.2f}"
                        print(f"       â€¢ {price['price']} ({price['type']}) - ç½®ä¿¡åº¦: {confidence_str}")
                    found_prices_count += len(keyword_prices)
                else:
                    print(f"     âŒ æœªæ‰¾åˆ°æœ‰æ•ˆä»·æ ¼")
                
                # é¿å…è¯·æ±‚è¿‡å¿«
                time.sleep(1.5)
            
            # å»é‡å’Œæ’åº
            unique_prices = self.deduplicate_prices_enhanced(all_prices)
            
            # åŠ¨æ€æ˜¾ç¤ºæœ€ç»ˆç»“æœ
            print(f"\nğŸ“Š çˆ¬å–ç»“æœæ±‡æ€»:")
            print(f"   ğŸ” æœç´¢å…³é”®è¯: {len(keywords)} ä¸ª")
            print(f"   ğŸ“„ æ€»æœç´¢ç»“æœ: {sum(len(self.search_bing_enhanced(k)) for k in keywords)} ä¸ª")
            print(f"   ğŸ’° åŸå§‹ä»·æ ¼æ•°: {found_prices_count} ä¸ª")
            print(f"   âœ… å»é‡åä»·æ ¼: {len(unique_prices)} ä¸ª")
            
            if unique_prices:
                print(f"   ğŸ“‹ æœ‰æ•ˆä»·æ ¼åˆ—è¡¨ (æŒ‰ç½®ä¿¡åº¦æ’åº):")
                for i, price in enumerate(unique_prices[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
                    confidence_str = f"{price['confidence']:.2f}"
                    print(f"     {i}. {price['price']} ({price['type']}) - ç½®ä¿¡åº¦: {confidence_str} - æ¥æº: {price['keyword']}")
                if len(unique_prices) > 5:
                    print(f"     ... è¿˜æœ‰ {len(unique_prices) - 5} ä¸ªä»·æ ¼")
            else:
                print(f"   âŒ æœªæ‰¾åˆ°æœ‰æ•ˆä»·æ ¼")
            
            # æ›´æ–°ç¼“å­˜
            success = self.update_price_cache_enhanced(court_data['detail_id'], unique_prices)
            
            if success:
                print(f"   ğŸ’¾ ç¼“å­˜æ›´æ–°: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
            else:
                print(f"   âŒ ç¼“å­˜æ›´æ–°å¤±è´¥")
            
            print(f"   {'âœ…' if success else 'âŒ'} åœºé¦† {court_name} çˆ¬å–{'å®Œæˆ' if success else 'å¤±è´¥'}")
            
            return {
                "court_id": court_data['court_id'],
                "court_name": court_name,
                "success": success,
                "prices": unique_prices,
                "keywords_used": keywords,
                "price_status": court_data['price_status'],
                "stats": {
                    "keywords_count": len(keywords),
                    "raw_prices_count": found_prices_count,
                    "unique_prices_count": len(unique_prices)
                }
            }
            
        except Exception as e:
            logger.error(f"å¢å¼ºçˆ¬å–åœºé¦† {court_name} ä»·æ ¼å¤±è´¥: {e}")
            print(f"   âŒ çˆ¬å–å¤±è´¥: {e}")
            return {
                "court_id": court_data['court_id'],
                "court_name": court_name,
                "success": False,
                "error": str(e)
            }
    
    def deduplicate_prices_enhanced(self, prices: List[Dict]) -> List[Dict]:
        """å¢å¼ºç‰ˆä»·æ ¼å»é‡ï¼ŒæŒ‰ç½®ä¿¡åº¦æ’åº"""
        unique_prices = []
        seen_prices = set()
        
        for price in prices:
            # æ›´ç²¾ç¡®çš„å»é‡é”®
            price_key = f"{price['type']}_{price['price']}_{price.get('keyword', '')}"
            if price_key not in seen_prices:
                unique_prices.append(price)
                seen_prices.add(price_key)
        
        # æŒ‰ç½®ä¿¡åº¦æ’åºï¼ˆç½®ä¿¡åº¦é«˜çš„åœ¨å‰ï¼‰
        unique_prices.sort(key=lambda x: x.get('confidence', 0), reverse=True)
        
        return unique_prices
    
    def update_price_cache_enhanced(self, detail_id: int, prices: List[Dict]) -> bool:
        """å¢å¼ºç‰ˆä»·æ ¼ç¼“å­˜æ›´æ–°"""
        try:
            detail = self.db.query(CourtDetail).filter(CourtDetail.id == detail_id).first()
            if detail:
                # åˆå¹¶ç°æœ‰BINGä»·æ ¼å’Œæ–°ä»·æ ¼
                existing_prices = []
                if detail.bing_prices:
                    try:
                        existing_prices = json.loads(detail.bing_prices)
                    except:
                        pass
                
                # åˆå¹¶ä»·æ ¼ï¼Œé¿å…é‡å¤
                all_prices = existing_prices + prices
                unique_prices = self.deduplicate_prices_enhanced(all_prices)
                
                detail.bing_prices = json.dumps(unique_prices, ensure_ascii=False)
                detail.updated_at = datetime.now()
                
                self.db.commit()
                logger.info(f"æˆåŠŸæ›´æ–°å¢å¼ºä»·æ ¼ç¼“å­˜: detail_id={detail_id}, ä»·æ ¼æ•°é‡: {len(unique_prices)}")
                return True
            else:
                logger.warning(f"æœªæ‰¾åˆ°è¯¦æƒ…è®°å½•: detail_id={detail_id}")
                return False
                
        except Exception as e:
            logger.error(f"æ›´æ–°å¢å¼ºä»·æ ¼ç¼“å­˜å¤±è´¥: {e}")
            self.db.rollback()
            return False
    
    def batch_crawl_prices_enhanced(self, limit: int = 100) -> dict:
        """å¢å¼ºç‰ˆæ‰¹é‡çˆ¬å–"""
        start_time = datetime.now()
        logger.info(f"å¼€å§‹å¢å¼ºç‰ˆBINGä»·æ ¼çˆ¬å–ï¼Œé™åˆ¶: {limit}")
        
        print(f"\nğŸš€ å¼€å§‹å¢å¼ºç‰ˆBINGä»·æ ¼çˆ¬å–")
        print(f"ğŸ“Š é™åˆ¶æ•°é‡: {limit}")
        print(f"â° å¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 60)
        
        # è®¾ç½®é©±åŠ¨
        self.setup_driver()
        
        try:
            courts = self.get_courts_for_enhanced_crawl()
            if not courts:
                logger.info("æ²¡æœ‰éœ€è¦å¢å¼ºçˆ¬å–ä»·æ ¼çš„åœºé¦†")
                print("âŒ æ²¡æœ‰éœ€è¦çˆ¬å–çš„åœºé¦†")
                return {"success": True, "message": "æ²¡æœ‰éœ€è¦çˆ¬å–çš„åœºé¦†"}
            
            courts = courts[:limit]
            results = []
            
            # å®æ—¶ç»Ÿè®¡
            total_success = 0
            total_failed = 0
            total_prices_found = 0
            
            print(f"ğŸ¯ æ‰¾åˆ° {len(courts)} ä¸ªéœ€è¦çˆ¬å–çš„åœºé¦†")
            print("=" * 60)
            
            for i, court in enumerate(courts):
                print(f"\n{'='*20} ç¬¬ {i+1}/{len(courts)} ä¸ªåœºé¦† {'='*20}")
                
                result = self.crawl_bing_prices_enhanced(court)
                results.append(result)
                
                # æ›´æ–°ç»Ÿè®¡
                if result['success']:
                    total_success += 1
                    prices_count = len(result.get('prices', []))
                    total_prices_found += prices_count
                    print(f"âœ… æˆåŠŸ! æ‰¾åˆ° {prices_count} ä¸ªä»·æ ¼")
                else:
                    total_failed += 1
                    print(f"âŒ å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                
                # æ˜¾ç¤ºå®æ—¶ç»Ÿè®¡
                print(f"\nğŸ“ˆ å®æ—¶ç»Ÿè®¡:")
                print(f"   âœ… æˆåŠŸ: {total_success}/{i+1}")
                print(f"   âŒ å¤±è´¥: {total_failed}/{i+1}")
                print(f"   ğŸ’° æ€»ä»·æ ¼: {total_prices_found} ä¸ª")
                print(f"   ğŸ“Š æˆåŠŸç‡: {total_success/(i+1)*100:.1f}%")
                
                # é¿å…è¯·æ±‚è¿‡å¿«
                time.sleep(2)
                
                # æ¯10ä¸ªè¯·æ±‚åç¨ä½œä¼‘æ¯
                if (i + 1) % 10 == 0:
                    print(f"\nâ¸ï¸  å·²å®Œæˆ {i+1} ä¸ªåœºé¦†ï¼Œä¼‘æ¯5ç§’...")
                    time.sleep(5)
            
            success_count = sum(1 for r in results if r['success'])
            failed_count = len(results) - success_count
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            # æœ€ç»ˆç»Ÿè®¡
            print(f"\n{'='*60}")
            print(f"ğŸ‰ å¢å¼ºç‰ˆBINGä»·æ ¼çˆ¬å–å®Œæˆ!")
            print(f"{'='*60}")
            print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
            print(f"   ğŸ¯ æ€»åœºé¦†æ•°: {len(results)}")
            print(f"   âœ… æˆåŠŸæ•°: {success_count}")
            print(f"   âŒ å¤±è´¥æ•°: {failed_count}")
            print(f"   ğŸ’° æ€»ä»·æ ¼æ•°: {total_prices_found}")
            print(f"   ğŸ“ˆ æˆåŠŸç‡: {success_count/len(results)*100:.1f}%")
            print(f"   â±ï¸  æ€»è€—æ—¶: {duration:.1f}ç§’")
            print(f"   ğŸš€ å¹³å‡é€Ÿåº¦: {len(results)/duration*60:.1f}ä¸ª/åˆ†é’Ÿ")
            
            # ä»·æ ¼åˆ†å¸ƒç»Ÿè®¡
            price_types = {}
            for result in results:
                if result['success']:
                    for price in result.get('prices', []):
                        price_type = price.get('type', 'æœªçŸ¥')
                        price_types[price_type] = price_types.get(price_type, 0) + 1
            
            if price_types:
                print(f"\nğŸ’° ä»·æ ¼ç±»å‹åˆ†å¸ƒ:")
                for price_type, count in sorted(price_types.items(), key=lambda x: x[1], reverse=True):
                    print(f"   {price_type}: {count} ä¸ª")
            
            summary = {
                "success": True,
                "total_courts": len(results),
                "success_count": success_count,
                "failed_count": failed_count,
                "total_prices_found": total_prices_found,
                "duration_seconds": duration,
                "success_rate": success_count/len(results)*100 if results else 0,
                "speed_per_minute": len(results)/duration*60 if duration > 0 else 0,
                "price_type_distribution": price_types,
                "results": results
            }
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"bing_price_results_enhanced_{timestamp}.json"
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2, default=str)
            logger.info(f"å¢å¼ºç‰ˆç»“æœå·²ä¿å­˜åˆ°: {filename}")
            print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {filename}")
            
            return summary
            
        finally:
            self.close_driver()

def main():
    """ä¸»å‡½æ•°"""
    spider = BingPriceSpiderEnhanced(headless=True)
    
    # å¢å¼ºç‰ˆæ‰¹é‡çˆ¬å–ä»·æ ¼ - çˆ¬å–æ‰€æœ‰éœ€è¦çˆ¬å–çš„åœºé¦†
    result = spider.batch_crawl_prices_enhanced(limit=1000)  # è®¾ç½®è¶³å¤Ÿå¤§çš„é™åˆ¶
    
    print(f"\n=== å¢å¼ºç‰ˆBINGä»·æ ¼çˆ¬å–å®Œæˆ ===")
    print(f"æ€»åœºé¦†æ•°: {result['total_courts']}")
    print(f"æˆåŠŸæ•°: {result['success_count']}")
    print(f"å¤±è´¥æ•°: {result['failed_count']}")
    print(f"è€—æ—¶: {result['duration_seconds']:.2f}ç§’")

if __name__ == "__main__":
    main() 